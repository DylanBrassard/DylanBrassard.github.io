[["index.html", "GLMM Walkthrough Preface Contents of this Document Structure of this Document", " GLMM Walkthrough Dylan Brassard 2022-04-12 Preface Photo Credit - Parks Canada/Dan Rafla Contents of this Document This document was created to communicate the steps in which I have taken to create my generalized linear mixed effects models for the first chapter of my masters thesis. Throughout this document I will be using data from my Lone Adult Black Bear data set to show my work and thought process. At the end of this document the reader will fully understand my modelling process, decisions, and results. Structure of this Document (Zuur and Ieno 2016) I will be following the 10 step protocol for conducting and presenting the results of regression analyses introduced by (Zuur and Ieno 2016) in the above paper. The protocol consists of the following steps which will also make up the first 10 sections of this document: State appropriate questions Visualize the experimental design Conduct data exploration Identify the dependency structure in the data Present the statistical model Fit the model Validate the model Interpret and present the numerical output of the model Create a visual representation of the model Simulate from the model In addition to the above steps being sections of this document I have also included a section titled Dredge which conveys some additional information regarding my models found using the package MuMIn (Barton 2020). References "],["state-appropriate-questions.html", "1 - State appropriate questions Primary Question Secondary Question", " 1 - State appropriate questions As advised by the protocol I will start with stating my research questions specific to this Adult Black Bear data set. Primary Question How has the Kenow wildfire impacted activity of adult black bears in Waterton Lakes National Park? Controlling for the influence of human recreation. Controlling for the influence of seasons on bear behavior. Secondary Question How does human recreation impact bear activity. "],["visualize-the-experimental-design.html", "2 - Visualize the Experimental Design Study Area Map Camera Effort Mapping", " 2 - Visualize the Experimental Design Study Area Map Figure - Waterton Lakes National Park (solid black outline) in southwestern Alberta. Black dashed grids represent 5x5 km camera deployment cells, each cell contains one camera (black and white triangles) within its bounds. The 2017 Kenow wildfire burn area is represented by the red polygon. Camera Effort Mapping In this section I will be creating maps for each time-period (Pre-fire/Post-fire) and each season (Spring/Summer/Autumn). Each map below shows the spatial layout of the cameras on the Waterton Lakes National Park landscape. The size of each point is representative of the number of days that camera was successfully operating in that specific time-period and season. (Note that in the code time-period is called Status in the code below, I will edit this at a later date.) Plots library(lattice) library(ggplot2) library(ggmap) library(maptools) library(sp) library(rgdal) library(knitr) # Reading in the weekly effort data, camera location data, and the Waterton Lakes National Park shapefile. Data&lt;-read.csv(&quot;./Data/3_Weekly_Effort.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Locations&lt;-read.csv(&quot;./Data/ParksCanadaCameraLocations.csv&quot;,header=TRUE,stringsAsFactors = FALSE) shpWaterton&lt;-readOGR(&quot;./Data/Waterton_Polygon/WatertonLakesNationalPark.shp&quot;) # Assigning the cordinate reference system the projection lat long in datum WGS 84 and naming this CRS WGS84 WGS84 &lt;-CRS(&quot;+proj=longlat +datum=WGS84&quot;) # Transforming the Waterton Lakes Shapefile into the appropriate coordinate reference system WatertonRePro&lt;-spTransform(shpWaterton,CRSobj = WGS84) # Fortifing the shapefile allowing it to be projected. This fortify causes the shapefile to become a dataframe. shapefileWaterton&lt;-fortify(WatertonRePro) # Keeping only the years of interest both pre and post fire. (Prefire = 2012-2014 and Postfire = 2018-2020) Dates&lt;-Data[which(Data$Year %in% c(&quot;2012&quot;,&quot;2013&quot;,&quot;2014&quot;,&quot;2018&quot;,&quot;2019&quot;,&quot;2020&quot;)),] # Aggregating the effort data accross camera codes, season, and time-periods Aggregated&lt;-aggregate(Effort_per_week ~ Camera_Code + Season + Status, data = Dates, sum) # Changing the column name (Name) in locations to Camera_Code for the merge names(Locations)[names(Locations) == &quot;Name&quot;] &lt;- &quot;Camera_Code&quot; # Joining the location data (latitude,longitude) to the effort data Merged&lt;-merge(Aggregated,Locations, by = &quot;Camera_Code&quot;) # Subsetting to only the required columns of data. S&lt;-Merged[,c(1:4,8:9)] # Changing the name of the &quot;effort per week&quot; column into just &quot;effort&quot; names(S)[names(S) == &quot;Effort_per_week&quot;] &lt;- &quot;Effort&quot; # Subsetting the data into seperate dataframes by season and time-period PreSpring&lt;-S[which(S$Season == &quot;Spring&quot; &amp; S$Status == &quot;Prefire&quot;),] PreSummer&lt;-S[which(S$Season == &quot;Summer&quot; &amp; S$Status == &quot;Prefire&quot;),] PreAutumn&lt;-S[which(S$Season == &quot;Autumn&quot; &amp; S$Status == &quot;Prefire&quot;),] PostSpring&lt;-S[which(S$Season == &quot;Spring&quot; &amp; S$Status == &quot;Postfire&quot;),] PostSummer&lt;-S[which(S$Season == &quot;Summer&quot; &amp; S$Status == &quot;Postfire&quot;),] PostAutumn&lt;-S[which(S$Season == &quot;Autumn&quot; &amp; S$Status == &quot;Postfire&quot;),] # Set a bounding box for the map. This is set to include all of Waterton plus some buffer. bbox&lt;-c(left = -114.2, bottom = 48.95, right = -113.6, top = 49.25) # Creating the maps for each time-period and season. This includes a terrain basemap from stamen maps. PreSpringEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PreSpring, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Pre-fire Spring Season Camera Effort&quot;) PreSummerEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PreSummer, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Pre-fire Summer Season Camera Effort&quot;) PreAutumnEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PreAutumn, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Pre-fire Autumn Season Camera Effort&quot;) PostSpringEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PostSpring, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Post-fire Spring Season Camera Effort&quot;) PostSummerEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PostSummer, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Post-fire Summer Season Camera Effort&quot;) PostAutumnEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PostAutumn, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Post-fire Autumn Season Camera Effort&quot;) Interpretation and Action It appears that there are some seasons which have low camera effort which is most likely due to a malfunctioning or non-operating camera, however, these differences in camera effort will be controlled for in my model by including an offset predictor of survey effort. These differences in effort should not affect the results of my models. "],["conduct-data-exploration.html", "3 - Conduct Data Exploration (Zuur, Ieno, and Elphick 2010) Protocol Outliers in the response and explanatory variables Homogeneity in the response variable Normality in the response Zero Trouble Y Collinearity in the response Relationships in the response and explanatory variables Interactions Independence in the response variable", " 3 - Conduct Data Exploration Before creating my first models I followed the data exploration protocol found in (Zuur, Ieno, and Elphick 2010). Due to the fact that three of my four predictor variables were categorical in nature and the protocol was developed primarily for continuous variables not all checks were applicable to my models. (Zuur, Ieno, and Elphick 2010) Protocol The 8 steps from the (Zuur, Ieno, and Elphick 2010) data exploration protocol include checking for: Outliers in the response and explanatory variables Homogeneity in the response variable Normality in the response Zero trouble in the response Collinearity in the response Relationships in the response and explanatory variables Interactions Independence in the response variable library(ggplot2) library(ggpubr) library(lattice) library(gridExtra) library(ape) library(tidyr) library(tidyverse) library(dplyr) library(knitr) library(ncf) # Reading in the adult black bear data and the camera locality data Bear&lt;-read.csv(&quot;./Data/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Locations&lt;-read.csv(&quot;./Data/ParksCanadaCameraLocations.csv&quot;,header=TRUE,stringsAsFactors = FALSE) # Setting Season as a factor and ordering it for future plots, this will allow for plots to be ordered in spring, summer, autumn Bear$Season&lt;-as.factor(Bear$Season) Bear$Season &lt;- ordered(Bear$Season, levels = c(&quot;Spring&quot;, &quot;Summer&quot;, &quot;Autumn&quot;)) # Separating pre-fire and post-fire data into separate data frames Pre&lt;-Bear[which(Bear$Status == &quot;Prefire&quot;),] Post&lt;-Bear[which(Bear$Status == &quot;Postfire&quot;),] head(Bear) ## Camera_Code Ordered_Week Species Region Lone_Adult Effort_per_week Season ## 1 H10 217 black Burnt 0 1 Spring ## 2 H10 218 black Burnt 0 7 Spring ## 3 H10 219 black Burnt 0 7 Spring ## 4 H10 220 black Burnt 0 7 Spring ## 5 H10 221 black Burnt 0 7 Spring ## 6 H10 222 black Burnt 0 7 Spring ## Status Group_Size Number_of_Groups ## 1 Prefire 1.818182 11 ## 2 Prefire 2.625000 16 ## 3 Prefire 2.666667 6 ## 4 Prefire 1.333333 6 ## 5 Prefire 2.750000 12 ## 6 Prefire 2.500000 4 Outliers in the response and explanatory variables The initial test suggested in the protocol is to test for outliers in both the response and continuous predictor variables. In order to check for outliers I plotted the frequency of both the number of weekly bear events and the number of weekly human groups as box and whisker plots and Cleveland dot plots. Plots # Box plot of the response variable (Number of adult black bears per week) boxplot(Bear$Lone_Adult, ylab = &quot;Number of events per week per camera&quot;, main = &quot;Weekly Number of Lone Adult Black Bear Events per Camera&quot;) # Boxplot of continuous variable (Number of human groups) boxplot(Bear$Number_of_Groups, ylab = &quot;Number of groups per week per camera&quot;, main = &quot;Weekly Number of Human Events per Camera&quot;) ggplot(Bear, aes(Lone_Adult,Camera_Code)) + geom_point(aes(color = Season), size = 2, position=position_dodge(width = 0.5)) + labs(title = &quot;Cleveland Dotplot of Weekly Lone Adult Black Bear Events per Camera&quot;, x = &quot;Number of Bear Events&quot;, y = &quot;Camera Code&quot;) ggplot(Bear, aes(Number_of_Groups,Camera_Code)) + geom_point(aes(color = Season), size = 2, position=position_dodge(width = 0.5))+ labs(title = &quot;Cleveland Dotplot of Weekly Human Events per Camera&quot;, x = &quot;Number of Human Events&quot;, y = &quot;Camera Code&quot;) Interpretation and Action It appears that there are not any outliers in the above plots. Although there are some cameras with high values in both the explanatory and response variables they do not appear to be outliers when compared to all other cameras. Furthermore, I believe that the higher counts on some cameras come from biologically relevant processes and do not represent inaccurate data. I will not be implementing any changes at this stage. Homogeneity in the response variable The suggested next step in the protocol is to check the homogeneity of variance in the response variable which is an important assumption for all regression related models. The protocol recommends using conditional box plots to test the response variable homogeneity. Plots # Response variable plotted by seasons Homogeneity1&lt;-bwplot(Lone_Adult ~ Season | Region * Status, data = Bear) Homogeneity2&lt;-bwplot(Lone_Adult ~ Season | Region, data = Bear) Homogeneity3&lt;-bwplot(Lone_Adult ~ Season | Status, data = Bear) Homogeneity4&lt;-bwplot(Lone_Adult ~ Status | Region, data = Bear) grid.arrange(Homogeneity1,Homogeneity2,Homogeneity3,Homogeneity4) Interpretation and Action The above plots suggest that there may be a violation in the assumption of homogeneity in the raw data. In all the above plots which contain season the season factor level of summer shows a noticeable difference in variance compared to spring and autumn. In the bottom right plot the burnt postfire data has a noticeably different variance than all the other factor levels in the plot. Both of these violations in homogeneity seem to be rather small and I will continue into the modeling process without making changes to this data because (Zuur, Ieno, and Elphick 2010) suggests that the verification of homogeneity needs to be done in the model residuals. I believe that my zero-inflated model will address this homogeneity problem and therefore I will make sure to verify this post-model fit. Normality in the response Many statistical tests assume that there is normality in the response variable and while there are regressions which can address non-normality there is still the requirement to specify the distribution of the response variable. The protocol recommends using histograms or QQ-plots to explore response variable distribution. I have a very strong feeling that this data will not be normally distributed as many count datasets are not and therefore I will not be using a QQ plot. I believe that the histogram will be more informative in displaying the distribution compared to the QQ plot. Plots # Plotting the weekly black bear event frequency into a histogram hist(Bear$Lone_Adult,breaks=seq(-1,16,1), label = TRUE, main = &quot;Frequancy Plot of Weekly Lone Black Bear Events&quot;, xlab = &quot;Number of Lone Adult Black Bear Events per Week&quot;) Pre&lt;-Bear[which(Bear$Status == &quot;Prefire&quot;),] # Histogram of only pre-fire data hist(Pre$Lone_Adult,breaks=seq(-1,16,1), label = TRUE) Post&lt;-Bear[which(Bear$Status == &quot;Postfire&quot;),] # Histogram of only post-fire data Normality3&lt;-hist(Post$Lone_Adult,breaks=seq(-1,16,1), label = TRUE) Interpretation and Action As anticipated, the response variable distribution appears to be either Poisson or negative binomial in nature. I will first fit the model using a Poisson distribution and will consider a negative binomial if there is over dispersion in the Poisson model. Zero Trouble Y Large amounts of zeros are common in ecological count data and can complicate statistical analyses if not accounted for. Large amounts of zeros can mean that a zero inflated model is needed, however, it does not mean that a zero-inflated model is necessarily required. The protocol suggests that histograms should be used to assess zero-trouble. These plots will be the same as the normality graphs found above. Plots # Plotting the weekly black bear event frequency into a histogram hist(Bear$Lone_Adult,breaks=seq(-1,16,1), label = TRUE, main = &quot;Frequancy Plot of Weekly Lone Black Bear Events&quot;, xlab = &quot;Number of Lone Adult Black Bear Events per Week&quot;) Pre&lt;-Bear[which(Bear$Status == &quot;Prefire&quot;),] # Histogram of only prefire data hist(Pre$Lone_Adult,breaks=seq(-1,16,1), label = TRUE) Post&lt;-Bear[which(Bear$Status == &quot;Postfire&quot;),] # Histogram of only postfire data hist(Post$Lone_Adult,breaks=seq(-1,16,1), label = TRUE) Interpretation and Action It appears that I may need to consider the use of a zero-inflated model. Although it seems evident looking at the above graphs that a zero-inflated model is needed I will first fit a Poisson model without a zero inflated term and formally test for zero-inflation in the fitted model. Collinearity in the response Due to my model only containing one continuous predictor I did not test for collinearity in predictors. Relationships in the response and explanatory variables The protocol suggests that all predictors should be plotted against the response variable. It is suggested that in order to explore the relationships we should use multi-panel scatter plots and conditional boxplots. Plots Relation1&lt;-ggplot(data = Bear, aes(x = Status, y = Lone_Adult)) + geom_boxplot() Relation2&lt;-ggplot(data = Bear, aes(x = Region, y = Lone_Adult)) + geom_boxplot() Relation3&lt;-ggplot(data = Bear, aes(x = Season, y = Lone_Adult)) + geom_boxplot() Relation4&lt;-ggplot(data = Bear, aes(x = Number_of_Groups, y = Lone_Adult)) + geom_point() + geom_smooth(method=&#39;lm&#39;) ggarrange(Relation1,Relation2,Relation3,Relation4) ## `geom_smooth()` using formula &#39;y ~ x&#39; Interpretation and Action These plots do not suggest any observable issues when plotting residuals against the predictors. The positive relationship between the number of bear events and the number of human groups is unexpected and should be explored further. Overall there are not any alarming trends or points in the plots above. Interactions The protocol states that all interactions should be tested in order to evaluate their incorporation into the model. In order to evaluate these interactions it is suggested that coplots are used. Below I have created coplots which plot the relationship of the continuous predictor and response predictor for each level of two of the categorical predictors. Due to three out of four of my predictors being categorical I also included box-plots testing the interactions of only the categorical predictors. Plots coplot(Lone_Adult~Number_of_Groups|Season * Region,data = Bear, xlab = &quot;Number_of_Groups&quot;, panel = function(x, y, ...) { tmp &lt;- lm(y ~ x, na.action = na.omit) points(x, y) }) coplot(Lone_Adult~Number_of_Groups|Season * Status,data = Bear, xlab = &quot;Number_of_Groups&quot;, panel = function(x, y, ...) { tmp &lt;- lm(y ~ x, na.action = na.omit) points(x, y) }) coplot(Lone_Adult~Number_of_Groups|Region * Status,data = Bear, xlab = &quot;Number_of_Groups&quot;, panel = function(x, y, ...) { tmp &lt;- lm(y ~ x, na.action = na.omit) points(x, y) }) Interaction4&lt;-ggplot(data = Bear, aes(x = Status, y = Lone_Adult)) + geom_boxplot() + geom_smooth(method=&quot;lm&quot;,aes(group=1)) Interaction4 + facet_grid(Season ~ Region) ## `geom_smooth()` using formula &#39;y ~ x&#39; Interaction5&lt;-ggplot(data = Bear, aes(x = Number_of_Groups, y = Lone_Adult)) + geom_point(stat = &quot;identity&quot;) + geom_smooth(method=&quot;lm&quot;) Interaction5 + facet_grid(Region ~ Season ~ Status) ## `geom_smooth()` using formula &#39;y ~ x&#39; Interpretation and Action It appears that there are some interesting interactions to keep in mind. It seems that there is a noticeable interaction of season with all other variables being considered. There may also be an interaction of region and time-period but it is difficult to interpret in the graphs due to the large amount of zeros. Overall, there does not appear to be any issues in the data in regards to interactions, during model fit these interactions will be explored further. Independence in the response variable The final step in the protocol is checking for independence in the response variable. For this study we will need to explore both the potential of spatial and temporal autocorrelation. In order to test for these we used spline correlograms for spatial autocorrelation and histograms for temporal autocorrelation. Plots # Aggregating the data into pre-fire and post-fire data-frames PreAgg&lt;-aggregate(Lone_Adult ~ Ordered_Week, data = Pre, sum) PreAggEffort&lt;-aggregate(Effort_per_week ~ Ordered_Week, data = Pre, sum) PreTotal&lt;-merge(PreAgg,PreAggEffort, by = &quot;Ordered_Week&quot;) PostAgg&lt;-aggregate(Lone_Adult ~ Ordered_Week, data = Post, sum) PostAggEffort&lt;-aggregate(Effort_per_week ~ Ordered_Week, data = Post, sum) PostTotal&lt;-merge(PostAgg,PostAggEffort, by = &quot;Ordered_Week&quot;) # Plotting the pre-fire data ggplot(data = PreTotal, aes(x = Ordered_Week, y = Lone_Adult)) + coord_cartesian(xlim =c(213, 367), ylim = c(0, 55)) + geom_col() + geom_vline(xintercept = c(218,231,245,258,270,283,297,310,322,335,349,362))+ geom_line(aes(y = Effort_per_week*0.1),colour = &quot;red&quot;, group = 1) + scale_y_continuous(sec.axis = sec_axis(trans = ~./5)) + ggtitle(&quot;Prefire Bear Events per week per year&quot;) # Plotting the post-fire data ggplot(data = PostTotal, aes(x = Ordered_Week, y = Lone_Adult)) + coord_cartesian(xlim =c(525, 679), ylim = c(0, 55)) + geom_col()+ geom_vline(xintercept = c(530,543,557,570,582,595,609,622,634,647,661,674))+ geom_line(aes(y = Effort_per_week*0.1),colour = &quot;blue&quot;, group = 1) + scale_y_continuous(sec.axis = sec_axis(trans = ~./5)) + ggtitle(&quot;Postfire Bear Events per week per year&quot;) # Spatial Autocorrelation using ncf colnames(Locations)[which(names(Locations) == &quot;Name&quot;)] &lt;- &quot;Camera_Code&quot; M&lt;-merge(Bear,Locations[,c(&quot;Camera_Code&quot;,&quot;Latitude&quot;,&quot;Longitude&quot;)], by = &quot;Camera_Code&quot;) Agged&lt;-aggregate(Lone_Adult~Camera_Code+Longitude+Latitude, data = M, sum) SpatialAutocorrelation &lt;- spline.correlog(Agged$Longitude,Agged$Latitude,Agged$Lone_Adult) Interpretation and Action In terms of the temporal autocorrelation there does not appear to be any issue. The distribution of bear events appears to follow an annual trend across all years as opposed to there being a clumping of events. In terms of spatial autocorrelation there appears to be a rather large effect in the raw data. If we were to observe no autocorrelation we would see a horizontal line at the value of zero. Despite this evidence of spatial autocorrelation in the raw data I believe that my final model will address this issue and I will further test the effect of spatial autocorrelation in the residuals of my model. References "],["identify-the-dependency-structure-in-the-data.html", "4 - Identify the Dependency Structure in the Data", " 4 - Identify the Dependency Structure in the Data We need to identify possible issues of pseudo-replication in the data. This data contains multiple observations per camera per week across both years and seasons. We will therefore fit a generalized linear mixed effects model with the term Camera ID specified as a random effect. This term will account for any possible pseudo-replication which would arise from having multiple sampling events for each camera (Due to the replication of camera ID in over both seasons and years). "],["present-the-statistical-model.html", "5 - Present the Statistical Model Response Variable Predictors Random Term", " 5 - Present the Statistical Model Response Variable In order to measure bear use intensity I will be using the number of bear events per week as my response variable. In order to calculate this I have binned all lone adult black bear events per week of the year for each year in my study. A reminder that that an event is defined as a capture of a black bear separated by 10 or more minutes from any other black bear events and that if two captures occur within 10 minutes it is considered one event. Response - Number of black bear events per week Predictors Categorical - Season (Spring/Summer/Autumn) - Status (Pre-fire/Post-fire) - Region (Burnt/Unburnt) Continuous - Number of Human Groups Offset - The log transformed number of active camera days per week The log transformation of offsets are required for generalized regressions with log link functions. Note Regarding Season We defined seasons based on the biology of the bears, with spring (March-May) representing the period when bears emerge from their dens and start to forage for food (Baldwin &amp; Bender, 2008; Craighead &amp; Craighead, 1972; Munro et al., 2006; Tietje &amp; Ruff, 1980; Vroom et al., 1980), summer (June-August) including the period of breeding and the start of hyperphagia (Baldwin &amp; Bender, 2008), and fall (September-November) representing the peak of hyperphagia and the period when bears start to move towards denning sites for winter (Baldwin &amp; Bender, 2008; Craighead &amp; Craighead, 1972; Munro et al., 2006; Tietje &amp; Ruff, 1980); Note: no bear events were reported from December to February in any year of the study and this is generally a period of minimal bear activity. Note about time-period The years of 2012-2014 are the pre-fire time-period while the years 2018-2020 are the post-fire. Random Term As discussed in the previous section we will be using the term Camera ID as a random term to account for multiple sampling at a location across seasons and years. This will account for this dependency and eliminate worry of pseudo-replication. Random Term - Camera ID "],["model-fit.html", "6 - Model Fit Choosing a Model Structure Model Selection A Point I am Struggling With", " 6 - Model Fit library(glmmTMB) library(lme4) library(DHARMa) library(ggplot2) library(performance) library(see) library(patchwork) library(MASS) library(lmtest) library(car) library(ggeffects) library(effects) setwd(&quot;D:/DataAndAnalysis&quot;) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Datasets/FinalDatasets/ForExploration/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) # Setting the predictors as factors for later functions Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Choosing a Model Structure In order to choose the appropriate model structure I followed instructions from (Zuur et al. 2009). I first fit a Poisson model to access zero-inflation and over dispersion. Models were fit using the full suite of predictors and their interactions which will be called the Global Model from here on out. FullModelPoisson&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Number_of_Groups*Status + Number_of_Groups*Region + Season*Status + Season*Region + Region*Status + Season*Status*Number_of_Groups + Season*Region*Number_of_Groups + Region*Status*Number_of_Groups + Season*Region*Status + Season*Region*Status*Number_of_Groups + offset(Effort_per_week) + (1|Camera_Code), data = Bear, na.action = na.pass, family = poisson()) #Check dispersion and zero inflation check_overdispersion(FullModelPoisson) ## # Overdispersion test ## ## dispersion ratio = 4.067 ## Pearson&#39;s Chi-Squared = 21154.005 ## p-value = &lt; 0.001 ## Overdispersion detected. check_zeroinflation(FullModelPoisson) ## # Check for zero-inflation ## ## Observed zeros: 3903 ## Predicted zeros: 3619 ## Ratio: 0.93 ## Model is underfitting zeros (probable zero-inflation). With evidence of both overdispersion and zero-inflation my next step was to fit a zero-inflated Poisson model. Zero-inflation can result in overdispersion, therefore by fitting a zero-inflated model I can retest for overdispersion and evaluate the goodness-of-fit. I also fit a zero-inflated negative binomial model and conducted a likelihood ratio test between the two zero-inflated global models using the package lmtest (Zeileis and Hothorn 2002) as recommended by (Zuur et al. 2009). ZiFullModelPoisson&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Number_of_Groups*Status + Number_of_Groups*Region + Season*Status + Season*Region + Region*Status + Season*Status*Number_of_Groups + Season*Region*Number_of_Groups + Region*Status*Number_of_Groups + Season*Region*Status + Season*Region*Status*Number_of_Groups + offset(Effort_per_week) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = poisson()) ZiFullModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Number_of_Groups*Status + Number_of_Groups*Region + Season*Status + Season*Region + Region*Status + Season*Status*Number_of_Groups + Season*Region*Number_of_Groups + Region*Status*Number_of_Groups + Season*Region*Status + Season*Region*Status*Number_of_Groups + offset(Effort_per_week) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1()) #Running a likelihood ratio test between the two zero inflated models lrtest(ZiFullModelPoisson,ZiFullModel) ## Likelihood ratio test ## ## Model 1: Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups * ## Season + Number_of_Groups * Status + Number_of_Groups * Region + ## Season * Status + Season * Region + Region * Status + Season * ## Status * Number_of_Groups + Season * Region * Number_of_Groups + ## Region * Status * Number_of_Groups + Season * Region * Status + ## Season * Region * Status * Number_of_Groups + offset(Effort_per_week) + ## (1 | Camera_Code) ## Model 2: Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups * ## Season + Number_of_Groups * Status + Number_of_Groups * Region + ## Season * Status + Season * Region + Region * Status + Season * ## Status * Number_of_Groups + Season * Region * Number_of_Groups + ## Region * Status * Number_of_Groups + Season * Region * Status + ## Season * Region * Status * Number_of_Groups + offset(Effort_per_week) + ## (1 | Camera_Code) ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 28 -4206.3 ## 2 29 -4114.8 1 182.98 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The likelihood ratio test showed that the variance structure of the Poisson model and the negative binomial model differed significantly. In the case of a significant likelihood ratio test (Zuur et al. 2009) states that the zero-inflated negative binomial model should be chosen as the correctly structured model. This is consistent with a priori knowledge that the negative binomial distribution is both effective and commonly used for count data with observable overdispersion (Bliss and Fisher 1953; Zuur et al. 2009). Model Selection In order to fit the appropriate model I used information from (Zuur et al. 2009) to complete backwards step-wise selection. When conducting backwards step wise selection I first started with a global model which contained all predictors of interest, and their interactions and proceed to drop terms from this model one at a time using the drop1 function in (2021) I dropped these terms one by one until the AIC no longer improved from dropping model terms, when this occurred I concluded it would be the final model. A Point I am Struggling With I have been reading about how step-wise selection is not the appropriate way to select a model and that instead a series of candidate models should be made and tested against one another (Information Theoretic Approach). At the same time I have been reading some literature saying that this information theoretic approach is also not best. I have decided to stick with the backwards step-wise selection for the time being as I know that it has lead to the best model through my dredge (found at the end of this document). Additionally, candidate models are normally created with apriori knowledge, however, I wonder if I could use this dredge output to evaluate models. In my thinking this would be the most robust way to conduct analysis assuming that all models are biologically relevant as all possible models are created. From my understanding this is usually not feasible due to the long computing times, however, I am able to complete these dredges in 11-15 hours. References "],["model-diagnostics.html", "7 - Model Diagnostics DHARMa Residual Package QQ and Residual Plot Outlier Plot and Test Dispersion Test Zero-Inflation Test Plotting Residuals Against Predictors", " 7 - Model Diagnostics DHARMa Residual Package In order to validate my fitted model I needed to conduct diagnostic tests on the model residuals as suggested in step 7 (Validate the Model) by (Zuur and Ieno 2016). It is common practice to use Pearson and deviance residuals when evaluating various regression methods. However, these residuals are not recommended in non-normally distributed model validation because they may not follow a normal distribution making the resulting plots difficult to interpret and possibly incorrect (Dunn and Smyth 1996; Feng, Li, and Sadeghpour 2020; Bai et al. 2021). It is suggested that the most efficient and reliable method for model validation is using randomized quantile residuals (RQR) which will follow a normal distribution when applied to a correct count regression model (Dunn and Smyth 1996; Feng, Li, and Sadeghpour 2020). RQRs are also recommended when modelling non-normal discrete response variables because Pearson and deviance residuals of these response variables will fall far from normality (Sadeghpour, 2016). We used the R package DHARMa (Hartig 2022) to calculate and plot RQRs for our final selected models. The DHARMa package simulates new response data from our fitted models and calculates scaled RQRs using this simulated data (Hartig 2022). library(glmmTMB) library(lme4) library(DHARMa) library(ggplot2) library(performance) library(see) library(patchwork) library(MASS) library(lmtest) library(car) library(ggeffects) library(effects) library(coefplot) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Data/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Season*Status + Season*Region + Region*Status + Season*Region*Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) QQ and Residual Plot Plot #Creating the simulated residuals from the final fitted model. SimulationOutput1&lt;-simulateResiduals(fittedModel = FinalModel,n = 2000) plot(SimulationOutput1) Interpretation and Action It appears that there are no significant issues with the residuals of this fitted model. Looking at the QQ plot there are no signs of over-dispersion or under-dispersion. The residual plot does not reveal a pattern in the RQR residuals and in fact the residuals seem to lie along the 0.50 mark. Due to the fact that these residuals are standardized to be between 0-1 this 0.5 value means that the residual is not negatively or positively valued. Outlier Plot and Test This outlier test is being conducted with a bootstrap method and a bootstrap value of 1000 (Hartig, n.d.). Plots testOutliers(SimulationOutput1, type = &quot;bootstrap&quot;,nBoot = 1000) Interpretation and Action The plots and test above suggest that there is no noticeable issues regarding outlying residuals in the model. Dispersion Test Plots testDispersion(SimulationOutput1) Interpretation and Action There does not appear to be any observable issues with over dispersion or under dispersion in the model. Zero-Inflation Test Plots testZeroInflation(SimulationOutput1) Interpretation and Action There does not appear to be any observable issues with zero-inflation in the model. Plotting Residuals Against Predictors testCategorical(SimulationOutput1,catPred = Bear$Season) testCategorical(SimulationOutput1,catPred = Bear$Status) testCategorical(SimulationOutput1,catPred = Bear$Region) GroupsResidualPlot&lt;-plotResiduals(SimulationOutput1,Bear$Number_of_Groups) SizeResidualPlot&lt;-plotResiduals(SimulationOutput1,Bear$Group_Size) Interpretation and Action There does not appear to be any issues in outliers when plotted against all predictors included and not included in the model. References "],["interpret-and-present-the-numerical-output-of-the-model.html", "8 - Interpret and Present the Numerical Output of the Model Interpreting the Model Summary Contrasting the Three-way Interaction of Region:Status:Season Interpreting the interaction effect of Season:Number of Groups Effect Size Joint Test Contrasting all other included interactions", " 8 - Interpret and Present the Numerical Output of the Model library(glmmTMB) library(ggplot2) library(car) library(ggeffects) library(effects) library(broom) library(broom.mixed) library(emmeans) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Data/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) # Designating the categorical predictors as factors which will allow us to order the factor levels within the model summary output Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season&lt;- factor(Bear$Season,levels = c(&quot;Spring&quot;,&quot;Summer&quot;,&quot;Autumn&quot;)) Bear$Status&lt;-relevel(Bear$Status,&quot;Prefire&quot;) Bear$Region&lt;-relevel(Bear$Region,&quot;Unburnt&quot;) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Season*Status + Season*Region + Region*Status + Season*Region*Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) Interpreting the Model Summary options(width = 100) summary(FinalModel) ## Family: nbinom1 ( log ) ## Formula: Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups * ## Season + Season * Status + Season * Region + Region * Status + ## Season * Region * Status + offset(log(Effort_per_week)) + (1 | Camera_Code) ## Zero inflation: ~Season ## Data: Bear ## ## AIC BIC logLik deviance df.resid ## 8177.5 8308.7 -4068.8 8137.5 5206 ## ## Random effects: ## ## Conditional model: ## Groups Name Variance Std.Dev. ## Camera_Code (Intercept) 0.8119 0.9011 ## Number of obs: 5226, groups: Camera_Code, 26 ## ## Dispersion parameter for nbinom1 family (): 0.564 ## ## Conditional model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.501708 0.297650 -8.405 &lt; 2e-16 *** ## RegionBurnt -0.780231 0.401609 -1.943 0.052044 . ## SeasonSummer 0.509452 0.167306 3.045 0.002327 ** ## SeasonAutumn -0.835532 0.230132 -3.631 0.000283 *** ## StatusPostfire -0.468390 0.177219 -2.643 0.008217 ** ## Number_of_Groups 0.022201 0.006280 3.535 0.000408 *** ## SeasonSummer:Number_of_Groups -0.024291 0.006182 -3.930 8.51e-05 *** ## SeasonAutumn:Number_of_Groups -0.020087 0.006850 -2.932 0.003363 ** ## SeasonSummer:StatusPostfire 0.178515 0.194352 0.919 0.358350 ## SeasonAutumn:StatusPostfire 0.447061 0.258648 1.728 0.083907 . ## RegionBurnt:SeasonSummer 0.742372 0.199203 3.727 0.000194 *** ## RegionBurnt:SeasonAutumn 1.113030 0.253152 4.397 1.10e-05 *** ## RegionBurnt:StatusPostfire 0.382298 0.264329 1.446 0.148094 ## RegionBurnt:SeasonSummer:StatusPostfire -0.660895 0.288971 -2.287 0.022192 * ## RegionBurnt:SeasonAutumn:StatusPostfire -0.957644 0.384019 -2.494 0.012640 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Zero-inflation model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.1583 0.1883 0.841 0.4003 ## SeasonSummer -2.7365 0.3748 -7.301 2.86e-13 *** ## SeasonAutumn -0.7621 0.3535 -2.156 0.0311 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This summary is messy and although you can interpret information from this summary output a more concise and clear method of interpreting the effect of the fire is to contrast the Region:Status:Season interaction term. In order to complete this I will be using the package emmeans (Lenth 2021). The emmeans package calculates the estimated marginal means from the a specified model while considering all predictors in the model using a reference grid. When creating the reference grid all used levels of a factor predictor are included as well as the average of each numeric predictor. The estimated marginal mean is calculated for each point within the reference grid meaning that each combination of predictors receives a value and each value in the grid is equally weighted. More information can be found here https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html Contrasting the Three-way Interaction of Region:Status:Season Not back transformed # Creating a emmeans object summary for the region:status interaction in each season. emm1&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season) X&lt;-contrast(emm1, method = &quot;pairwise&quot;) summary(emm1) ## Season = Spring: ## Region Status emmean SE df lower.CL upper.CL ## Unburnt Prefire -0.4124 0.293 5206 -0.987 0.162 ## Burnt Prefire -1.1927 0.297 5206 -1.776 -0.610 ## Unburnt Postfire -0.8808 0.296 5206 -1.460 -0.301 ## Burnt Postfire -1.2788 0.299 5206 -1.864 -0.693 ## ## Season = Summer: ## Region Status emmean SE df lower.CL upper.CL ## Unburnt Prefire -0.0838 0.258 5206 -0.590 0.423 ## Burnt Prefire -0.1216 0.258 5206 -0.628 0.385 ## Unburnt Postfire -0.3736 0.260 5206 -0.883 0.136 ## Burnt Postfire -0.6901 0.262 5206 -1.204 -0.176 ## ## Season = Autumn: ## Region Status emmean SE df lower.CL upper.CL ## Unburnt Prefire -1.3975 0.304 5206 -1.994 -0.801 ## Burnt Prefire -1.0647 0.302 5206 -1.656 -0.473 ## Unburnt Postfire -1.4188 0.306 5206 -2.019 -0.818 ## Burnt Postfire -1.6613 0.328 5206 -2.304 -1.018 ## ## Results are given on the log (not the response) scale. ## Confidence level used: 0.95 Interpretation Looking at these emmeans we can see the estimated marginal mean of each of the predictor combinations. This table tells us that in the spring the unburnt region prefire had the most bear events, while the burnt postfire had the least bear events. In the summer the unburnt region prefire had the most bear events and the burnt postfire had the least. Lastly in Autumn the prefire burnt region has the most bear events and the burnt region postfire has the least. # Presenting the contrasts with 95% confidence intervals confint(X) ## Season = Spring: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.7802 0.4016 5206 -0.2518 1.812 ## Unburnt Prefire - Unburnt Postfire 0.4684 0.1772 5206 0.0130 0.924 ## Unburnt Prefire - Burnt Postfire 0.8663 0.4025 5206 -0.1680 1.901 ## Burnt Prefire - Unburnt Postfire -0.3118 0.4037 5206 -1.3494 0.726 ## Burnt Prefire - Burnt Postfire 0.0861 0.1950 5206 -0.4149 0.587 ## Unburnt Postfire - Burnt Postfire 0.3979 0.4052 5206 -0.6433 1.439 ## ## Season = Summer: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.0379 0.3641 5206 -0.8977 0.973 ## Unburnt Prefire - Unburnt Postfire 0.2899 0.0797 5206 0.0850 0.495 ## Unburnt Prefire - Burnt Postfire 0.6063 0.3665 5206 -0.3354 1.548 ## Burnt Prefire - Unburnt Postfire 0.2520 0.3648 5206 -0.6855 1.189 ## Burnt Prefire - Burnt Postfire 0.5685 0.0859 5206 0.3478 0.789 ## Unburnt Postfire - Burnt Postfire 0.3165 0.3673 5206 -0.6275 1.260 ## ## Season = Autumn: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire -0.3328 0.3949 5206 -1.3476 0.682 ## Unburnt Prefire - Unburnt Postfire 0.0213 0.1886 5206 -0.4633 0.506 ## Unburnt Prefire - Burnt Postfire 0.2639 0.4145 5206 -0.8014 1.329 ## Burnt Prefire - Unburnt Postfire 0.3541 0.3990 5206 -0.6712 1.379 ## Burnt Prefire - Burnt Postfire 0.5967 0.2053 5206 0.0691 1.124 ## Unburnt Postfire - Burnt Postfire 0.2425 0.4185 5206 -0.8329 1.318 ## ## Results are given on the log (not the response) scale. ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates Interpretation In the spring season we see decreases in bear event intensity across both regions in the post-fire landscape. This decrease in bear event intensity is greatest in the unburnt region. Across regions in the pre-fire time period we see a greater intensity in bear activity in the unburnt landscape compared to postfire. Along with a decrease of bear activity intensity in the pos-fire landscape we also see a reduced usage of the unburnt region compared to the burnt region in the postfire landscape. We see that when we contrast the unburnt region across time-periods we have significant decreases in black bear event intensity. In the summer season we see decreases in bear event intensity in both regions in the post-fire landscape. This decrease in bear event intensity is greatest in the burnt region. Across regions in the post-fire time period we see a greater intensity in bear activity in the unburnt landscape compared to postfire. Although overall bear event intensity decreases postfire we see an increased use of the unburnt region compared to the burnt region. We see that when we contrast both the unburnt and burnt regions across time-periods we have significant decreases in black bear event intensity. In the autumn season we see a decrease in bear event intensity in both the unburnt and burnt regions postfire. We see a high use of the burnt landscape in the prefire landscape while in the postfire landscape there is an increase in the usage of the unburnt region. We see that when we contrast the burnt region across time-periods we have significant decreases in black bear event intensity. Back transformed # Creating a emmeans object which contrasts the response variable values of region and status for each season. This represents the BACKTRANSFORMED results. emm3&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season, type = &quot;response&quot;) Z&lt;-contrast(regrid(emm3), method = &quot;pairwise&quot;) summary(emm3) ## Season = Spring: ## Region Status response SE df lower.CL upper.CL ## Unburnt Prefire 0.662 0.1939 5206 0.3729 1.175 ## Burnt Prefire 0.303 0.0902 5206 0.1694 0.543 ## Unburnt Postfire 0.414 0.1225 5206 0.2322 0.740 ## Burnt Postfire 0.278 0.0831 5206 0.1550 0.500 ## ## Season = Summer: ## Region Status response SE df lower.CL upper.CL ## Unburnt Prefire 0.920 0.2377 5206 0.5541 1.526 ## Burnt Prefire 0.885 0.2289 5206 0.5335 1.470 ## Unburnt Postfire 0.688 0.1788 5206 0.4136 1.145 ## Burnt Postfire 0.502 0.1316 5206 0.2999 0.839 ## ## Season = Autumn: ## Region Status response SE df lower.CL upper.CL ## Unburnt Prefire 0.247 0.0752 5206 0.1362 0.449 ## Burnt Prefire 0.345 0.1040 5206 0.1909 0.623 ## Unburnt Postfire 0.242 0.0741 5206 0.1328 0.441 ## Burnt Postfire 0.190 0.0623 5206 0.0998 0.361 ## ## Confidence level used: 0.95 ## Intervals are back-transformed from the log scale # Presenting the results with 95% confidence intervals confint(Z) ## Season = Spring: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.35863 0.2077 5206 -0.17514 0.892 ## Unburnt Prefire - Unburnt Postfire 0.24760 0.1171 5206 -0.05333 0.549 ## Unburnt Prefire - Burnt Postfire 0.38366 0.2052 5206 -0.14370 0.911 ## Burnt Prefire - Unburnt Postfire -0.11103 0.1468 5206 -0.48817 0.266 ## Burnt Prefire - Burnt Postfire 0.02503 0.0571 5206 -0.12171 0.172 ## Unburnt Postfire - Burnt Postfire 0.13606 0.1431 5206 -0.23175 0.504 ## ## Season = Summer: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.03417 0.3286 5206 -0.81040 0.879 ## Unburnt Prefire - Unburnt Postfire 0.23142 0.0866 5206 0.00897 0.454 ## Unburnt Prefire - Burnt Postfire 0.41812 0.2706 5206 -0.27718 1.113 ## Burnt Prefire - Unburnt Postfire 0.19726 0.2891 5206 -0.54581 0.940 ## Burnt Prefire - Burnt Postfire 0.38395 0.1129 5206 0.09394 0.674 ## Unburnt Postfire - Burnt Postfire 0.18670 0.2209 5206 -0.38098 0.754 ## ## Season = Autumn: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire -0.09762 0.1188 5206 -0.40304 0.208 ## Unburnt Prefire - Unburnt Postfire 0.00522 0.0461 5206 -0.11335 0.124 ## Unburnt Prefire - Burnt Postfire 0.05734 0.0906 5206 -0.17547 0.290 ## Burnt Prefire - Unburnt Postfire 0.10284 0.1191 5206 -0.20315 0.409 ## Burnt Prefire - Burnt Postfire 0.15496 0.0667 5206 -0.01653 0.326 ## Unburnt Postfire - Burnt Postfire 0.05212 0.0904 5206 -0.18010 0.284 ## ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates Interpretation In the back transformed results we can only see significant results in the Summer Unburnt and Burnt regions. By my understanding these estimate values represent the response variable (Indicated by type = response) meaning that the estimate is the change in the number of bear events per week per camera. If this is the case then we would see the following decreases in bear use intensity after the fire as represented by the number of bear events captured per camera per week. Spring Unburnt - 0.248 (-0.053/0.549) Burnt - 0.025 (-0.122/0.172) Summer Unburnt - 0.231 (0.009/0.454) Burnt - 0.384 (0.094/0.674) Autumn Unburnt - 0.005 (-0.113/0.124) Burnt - 0.155 (-0.017/0.326) In addition to these results we do not see any significant contrasts of region between pre and post fire in any season as opposed to the log transformed results above. This suggests that adult black bears have not used the two regions differently pre-fire compared to post-fire. Interpreting the interaction effect of Season:Number of Groups Using the emtrends function from the (Lenth 2021) function we can calculate the effect of the number of human groups on bear activity for each season. emtrends(FinalModel, pairwise ~ Season, var = &quot;Number_of_Groups&quot;) ## $emtrends ## Season Number_of_Groups.trend SE df lower.CL upper.CL ## Spring 0.02220 0.00628 5206 0.00989 0.034512 ## Summer -0.00209 0.00114 5206 -0.00433 0.000147 ## Autumn 0.00211 0.00317 5206 -0.00411 0.008335 ## ## Results are averaged over the levels of: Region, Status ## Confidence level used: 0.95 ## ## $contrasts ## contrast estimate SE df t.ratio p.value ## Spring - Summer 0.0243 0.00618 5206 3.930 0.0003 ## Spring - Autumn 0.0201 0.00685 5206 2.932 0.0095 ## Summer - Autumn -0.0042 0.00323 5206 -1.301 0.3947 ## ## Results are averaged over the levels of: Region, Status ## P value adjustment: tukey method for comparing a family of 3 estimates Interpretation We can see that both spring and autumn have positive relationships between the number of human groups using a trail and the number of bears using the trail. Summer meanwhile shows a negative trend which is much more expected. Looking at the confidence intervals the spring season is the only season which shows a significant relationship between human groups and bear groups. Meanwhile if we look at the contrasts we can see that the effect seen in spring is significantly different than the effects seen in both summer and autumn while the contrast between autumn and summer appears to not be significant. Effect Size The following code calculates the effect sizes of each contrast using the function eff_size from the package (Lenth 2021). EFF1&lt;-eff_size(emm3, sigma = sigma(FinalModel), edf = Inf, method = &quot;pairwise&quot;) summary(EFF1) ## Season = Spring: ## contrast effect.size SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 1.3823 0.712 5206 -0.0126 2.777 ## Unburnt Prefire - Unburnt Postfire 0.8298 0.314 5206 0.2143 1.445 ## Unburnt Prefire - Burnt Postfire 1.5349 0.713 5206 0.1369 2.933 ## Burnt Prefire - Unburnt Postfire -0.5525 0.715 5206 -1.9547 0.850 ## Burnt Prefire - Burnt Postfire 0.1525 0.345 5206 -0.5246 0.830 ## Unburnt Postfire - Burnt Postfire 0.7050 0.718 5206 -0.7022 2.112 ## ## Season = Summer: ## contrast effect.size SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.0671 0.645 5206 -1.1974 1.332 ## Unburnt Prefire - Unburnt Postfire 0.5136 0.141 5206 0.2367 0.790 ## Unburnt Prefire - Burnt Postfire 1.0742 0.649 5206 -0.1986 2.347 ## Burnt Prefire - Unburnt Postfire 0.4465 0.646 5206 -0.8205 1.714 ## Burnt Prefire - Burnt Postfire 1.0072 0.152 5206 0.7089 1.305 ## Unburnt Postfire - Burnt Postfire 0.5607 0.651 5206 -0.7151 1.836 ## ## Season = Autumn: ## contrast effect.size SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire -0.5896 0.700 5206 -1.9612 0.782 ## Unburnt Prefire - Unburnt Postfire 0.0378 0.334 5206 -0.6172 0.693 ## Unburnt Prefire - Burnt Postfire 0.4675 0.734 5206 -0.9723 1.907 ## Burnt Prefire - Unburnt Postfire 0.6274 0.707 5206 -0.7584 2.013 ## Burnt Prefire - Burnt Postfire 1.0571 0.364 5206 0.3441 1.770 ## Unburnt Postfire - Burnt Postfire 0.4297 0.741 5206 -1.0238 1.883 ## ## sigma used for effect sizes: 0.5644 ## Confidence level used: 0.95 Interpretation I am unsure how to interpret the results from the effect size function at this time. I had originally thought that by back transforming my estimated marginal means (as above) I had received my effect sizes, however, these differ from the effect size function found above. I assume that these values should be the same however that may be incorrect and I will look into that further. Joint Test joint_tests(FinalModel, by = &quot;Season&quot;) ## Season = Spring: ## model term df1 df2 F.ratio p.value ## Region 1 5206 2.389 0.1222 ## Status 1 5206 4.458 0.0348 ## Number_of_Groups 1 5206 12.497 0.0004 ## Region:Status 1 5206 2.092 0.1482 ## ## Season = Summer: ## model term df1 df2 F.ratio p.value ## Region 1 5206 0.241 0.6236 ## Status 1 5206 53.967 &lt;.0001 ## Number_of_Groups 1 5206 3.355 0.0671 ## Region:Status 1 5206 5.623 0.0178 ## ## Season = Autumn: ## model term df1 df2 F.ratio p.value ## Region 1 5206 0.014 0.9060 ## Status 1 5206 4.919 0.0266 ## Number_of_Groups 1 5206 0.444 0.5053 ## Region:Status 1 5206 4.257 0.0391 Contrasting all other included interactions RegionSeason&lt;-emmeans(FinalModel,spec = ~ Region:Season, type = &quot;response&quot;) RSea&lt;-contrast(regrid(RegionSeason), method = &quot;pairwise&quot;) confint(RSea) ## contrast estimate SE df lower.CL upper.CL ## Unburnt Spring - Burnt Spring 0.2332 0.1623 5206 -0.22958 0.6959 ## Unburnt Spring - Unburnt Summer -0.2718 0.1006 5206 -0.55866 0.0152 ## Unburnt Spring - Burnt Summer -0.1426 0.2251 5206 -0.78422 0.4990 ## Unburnt Spring - Unburnt Autumn 0.2792 0.1012 5206 -0.00925 0.5677 ## Unburnt Spring - Burnt Autumn 0.2679 0.1648 5206 -0.20188 0.7377 ## Burnt Spring - Unburnt Summer -0.5049 0.2193 5206 -1.12998 0.1201 ## Burnt Spring - Burnt Summer -0.3758 0.1060 5206 -0.67796 -0.0736 ## Burnt Spring - Unburnt Autumn 0.0460 0.1082 5206 -0.26240 0.3545 ## Burnt Spring - Burnt Autumn 0.0347 0.0552 5206 -0.12262 0.1921 ## Unburnt Summer - Burnt Summer 0.1292 0.2648 5206 -0.62576 0.8841 ## Unburnt Summer - Unburnt Autumn 0.5510 0.1478 5206 0.12974 0.9722 ## Unburnt Summer - Burnt Autumn 0.5397 0.2174 5206 -0.08009 1.1594 ## Burnt Summer - Unburnt Autumn 0.4218 0.1853 5206 -0.10648 0.9501 ## Burnt Summer - Burnt Autumn 0.4105 0.1163 5206 0.07893 0.7421 ## Unburnt Autumn - Burnt Autumn -0.0113 0.0958 5206 -0.28426 0.2617 ## ## Results are averaged over the levels of: Status ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 6 estimates StatusSeason&lt;-emmeans(FinalModel,spec = ~ Status:Season, type = &quot;response&quot;) StatSea&lt;-contrast(regrid(StatusSeason), method = &quot;pairwise&quot;) confint(StatSea) ## contrast estimate SE df lower.CL upper.CL ## Prefire Spring - Postfire Spring 0.1085 0.0562 5206 -0.0517 0.2687 ## Prefire Spring - Prefire Summer -0.4542 0.1042 5206 -0.7512 -0.1573 ## Prefire Spring - Postfire Summer -0.1393 0.0666 5206 -0.3292 0.0506 ## Prefire Spring - Prefire Autumn 0.1562 0.0737 5206 -0.0538 0.3662 ## Prefire Spring - Postfire Autumn 0.2338 0.0764 5206 0.0160 0.4516 ## Postfire Spring - Prefire Summer -0.5627 0.1150 5206 -0.8906 -0.2348 ## Postfire Spring - Postfire Summer -0.2478 0.0677 5206 -0.4409 -0.0548 ## Postfire Spring - Prefire Autumn 0.0477 0.0596 5206 -0.1222 0.2175 ## Postfire Spring - Postfire Autumn 0.1253 0.0583 5206 -0.0408 0.2914 ## Prefire Summer - Postfire Summer 0.3149 0.0708 5206 0.1131 0.5167 ## Prefire Summer - Prefire Autumn 0.6104 0.1232 5206 0.2592 0.9617 ## Prefire Summer - Postfire Autumn 0.6880 0.1333 5206 0.3080 1.0681 ## Postfire Summer - Prefire Autumn 0.2955 0.0742 5206 0.0841 0.5069 ## Postfire Summer - Postfire Autumn 0.3731 0.0807 5206 0.1430 0.6033 ## Prefire Autumn - Postfire Autumn 0.0776 0.0383 5206 -0.0314 0.1867 ## ## Results are averaged over the levels of: Region ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 6 estimates RegionStatus&lt;-emmeans(FinalModel,spec = ~ Region:Status, type = &quot;response&quot;) RStat&lt;-contrast(regrid(RegionStatus), method = &quot;pairwise&quot;) confint(RStat) ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.0795 0.1811 5206 -0.3860 0.545 ## Unburnt Prefire - Unburnt Postfire 0.1217 0.0529 5206 -0.0142 0.258 ## Unburnt Prefire - Burnt Postfire 0.2338 0.1591 5206 -0.1750 0.643 ## Burnt Prefire - Unburnt Postfire 0.0423 0.1587 5206 -0.3657 0.450 ## Burnt Prefire - Burnt Postfire 0.1543 0.0538 5206 0.0160 0.293 ## Unburnt Postfire - Burnt Postfire 0.1120 0.1326 5206 -0.2287 0.453 ## ## Results are averaged over the levels of: Season ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates References "],["create-a-visual-repersentation-of-the-model.html", "9 - Create a Visual Repersentation of the Model Visualizing the three-way interaction of Season:Status:Region Visualizing the two-way human use and season interaction Effect Size Plotting all other included interaction terms", " 9 - Create a Visual Repersentation of the Model library(glmmTMB) library(ggplot2) library(car) library(ggeffects) library(effects) library(broom) library(broom.mixed) library(emmeans) setwd(&quot;D:/DataAndAnalysis&quot;) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Datasets/FinalDatasets/ForExploration/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season&lt;- factor(Bear$Season,levels = c(&quot;Spring&quot;,&quot;Summer&quot;,&quot;Autumn&quot;)) Bear$Status&lt;-relevel(Bear$Status,&quot;Prefire&quot;) Bear$Region&lt;-relevel(Bear$Region,&quot;Unburnt&quot;) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Season*Status + Season*Region + Region*Status + Season*Region*Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) Visualizing the three-way interaction of Season:Status:Region I will be using the function emmip to create interaction plots of the estimated margnial means based on the fitted model. This is from the package emmeans emmip(FinalModel,~Region~Status|Season, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) Interpretation The above plot shows that in all three seasons there are decreases in bear use intensity in the postfire landscape, however, the magnitude of these decreases vary based on both region and season. It appears that in each season there is not a significant decrease between prefire and postfire bear intensity for any region however this is at odds with the emmeans output from section 08. I need to look more at the response variable here compared to the table in section 8. These estimates do not appear to match up and therefore I think I need to look further into this. Visualizing the two-way human use and season interaction emmip(FinalModel, Season ~ Number_of_Groups, at = list(Number_of_Groups = c(0,1,5,10,15,20,30,40,50,60,70,80,90,100), CIs = TRUE, type = &quot;re&quot;))+ theme_bw(base_size = 20) Interpretation As we can see in the plot above there is very different effects of the number of human groups on bear use intensity along all of the seasons. Both spring and autumn see a positive relationship of human usage and bear usage while summer sees a negative relationship. I think that a reason we may see the positive relationships in spring and autumn is that generally both humans and bears will be more active during the nicer portions of the seasons. In early spring for example few humans will be hiking on trails and bears may still be denned or will only start emerging from dens. As spring warms more humans will be hiking and more bears will be leaving their dens in search of food. Effect Size The following code plots the effect sizes of each contrast using the function eff_size from the package emmeans. emm3&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season, type = &quot;response&quot;) EFF1&lt;-eff_size(emm3, sigma = sigma(FinalModel), edf = Inf, method = &quot;pairwise&quot;) plot(EFF1) Interpretation I am unsure how to interpret the results from the effect size function at this time. I had originally thought that by back transforming my emmeans (as above) I had received my effect sizes, however, these differ from the effect size function found above. I assume that these values should be the same however that may be incorrect and I will look into that further. Plotting all other included interaction terms I do not think that the other plots on this page will be as important as those above becuase those above are the highest ordered interactions. I will still present the interactions below incase they are usefull. emmip(FinalModel, Region~Season, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) ## NOTE: Results may be misleading due to involvement in interactions emmip(FinalModel, Status~Season, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) ## NOTE: Results may be misleading due to involvement in interactions emmip(FinalModel, Region~Status, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) ## NOTE: Results may be misleading due to involvement in interactions "],["simulate-from-the-model.html", "10 - Simulate from the Model", " 10 - Simulate from the Model "],["bonus---dredging-model-possibilities-with-mumin.html", "Bonus - Dredging model possibilities with MuMIn Code Table Interpretation", " Bonus - Dredging model possibilities with MuMIn I completed model dredging with the command dredge in the package MuMin to create a set of models with all possible combinations of fixed effects terms found in my global model. When creating this dredge I set the inclusion of the zero-inflation factor and the offset term as required which means they are present in all the models of the dredge. The dredge function calculates each models log-likelihood, AICc, delta AICc, and the weight against all other models. I will include the code which I used to complete the dredge function and a table of all models within a delta 2 AICc. Running the function of the dredge takes upwards of 12 hours and therefore I will not include the entire output here, however, I do have a copy saved seperatly. Code library(glmmTMB) library(MuMIn) setwd(&quot;D:/DataAndAnalysis&quot;) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Datasets/FinalDatasets/ForExploration/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season&lt;- factor(Bear$Season,levels = c(&quot;Spring&quot;,&quot;Summer&quot;,&quot;Autumn&quot;)) Bear$Status&lt;-relevel(Bear$Status,&quot;Prefire&quot;) Bear$Region&lt;-relevel(Bear$Region,&quot;Unburnt&quot;) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Season*Status + Season*Region + Region*Status + Season*Region*Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) #Completing the dredge Dredge&lt;-dredge(FinalModel, fixed = c(&quot;cond(offset(Effort_per_week))&quot;,&quot;zi(Season)&quot;)) Table cond.Int zi.Int disp.Int Humans Region Season Status Humans.Region Humans.Season Humans.Status Region.Season Region.Status Season.Status Humans.Region.Season Humans.Region.Status Humans.Season.Status Region.Season.Status Humans.Season.Status.Region offset zi df logLik AICc delta weight -3.601090 -0.6037293 0.0021143 NA NA NA NA NA NA 20 -4068.751 8177.664 0.0000000 0.1836902 -3.529966 -0.5762859 0.0022761 NA NA NA NA NA NA NA NA 16 -4072.920 8177.944 0.2798567 0.1597040 -3.602903 -0.6110782 0.0015810 NA NA NA NA NA 21 -4068.571 8179.320 1.6563612 0.0802438 -3.533596 -0.5827482 0.0017774 NA NA NA NA NA NA NA 17 -4072.759 8179.636 1.9716238 0.0685414 -3.602365 -0.6049524 0.0022582 NA NA NA NA NA 21 -4068.742 8179.662 1.9980601 0.0676414 Interpretation The dredge was completed for all possible models and these 5 models represent a weight of 0.559821 out of 335 total models. Both the top model and the next best model have similar weights (0.184 vs 0.160) which makes me wonder if I need to consider model averaging or something similar. All models share the following predictors: Human groups Region Season Status As well as the following interactions Human Groups:Season Region:Season Region:Status (Fire Effect) All models do not include: Human Groups:Region:Season Human Groups:Region:Status Human Groups:Season:Status Human Groups:Season:Status:Region "],["references.html", "References", " References "]]
