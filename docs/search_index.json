[["index.html", "GLMM Walkthrough Preface Contents of this Document Structure of this Document", " GLMM Walkthrough Dylan Brassard 2022-04-24 Preface Contents of this Document This document was created to communicate the steps in which I have taken to create my generalized linear mixed effects models for the first chapter of my masters thesis. Throughout this document I will be using data from my Lone Adult Black Bear data set to show my work and thought process. At the end of this document the reader will fully understand my modelling process, decisions, and results. Structure of this Document (Zuur and Ieno 2016) I will be following the 10 step protocol for conducting and presenting the results of regression analyses introduced by (Zuur and Ieno 2016) in the above paper. The protocol consists of the following steps which will also make up the first 10 sections of this document: State appropriate questions Visualize the experimental design Conduct data exploration Identify the dependency structure in the data Present the statistical model Fit the model Validate the model Interpret and present the numerical output of the model Create a visual representation of the model Simulate from the model In addition to the above steps being sections of this document I have also included a section titled Dredge which conveys some additional information regarding my models found using the package MuMIn (Barton 2020). References "],["state-appropriate-questions.html", "1 - State Appropriate Questions Primary Question Secondary Questions", " 1 - State Appropriate Questions Primary Question How has the Kenow wildfire impacted the activity of bears in Waterton Lakes National Park? With consideration of the influence of human recreation on bears. With consideration of the influence of seasons on bear behavior. Secondary Questions Are effects of the Kenow wildfire moderated by human recreation? Are effects of the Kenow wildfire moderated by season? "],["visualize-the-experimental-design.html", "2 - Visualize the Experimental Design Study Area Map Camera Effort (Sampling Time)", " 2 - Visualize the Experimental Design Study Area Map Figure - Waterton Lakes National Park (solid black outline) in southwestern Alberta. Black dashed grids represent 5x5 km camera deployment cells, each cell contains one camera (black and white triangles) within its bounds. The 2017 Kenow wildfire burn area is represented by the red polygon. Camera Effort (Sampling Time) In this section I will be creating maps for each time-period (Pre-fire/Post-fire) and each season (Spring/Summer/Autumn). Each map below shows the spatial layout of the cameras on the Waterton Lakes National Park landscape. The size of each point is representative of the number of days that camera was successfully operating in that specific time-period and season. (Note that in the code time-period is called Status, I will edit this at a later date) Preparing the Data library(lattice) library(ggplot2) library(ggmap) library(maptools) library(sp) library(rgdal) library(knitr) # Reading in the weekly effort data, camera location data, and the Waterton Lakes National Park (WLNP) shapefile. Data&lt;-read.csv(&quot;./Data/3_Weekly_Effort.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Locations&lt;-read.csv(&quot;./Data/ParksCanadaCameraLocations.csv&quot;,header=TRUE,stringsAsFactors = FALSE) shpWaterton&lt;-readOGR(&quot;./Data/Waterton_Polygon/WatertonLakesNationalPark.shp&quot;) # Assigning the coordinate reference system the projection lat long in datum WGS 84. WGS84 &lt;-CRS(&quot;+proj=longlat +datum=WGS84&quot;) # Transforming the Waterton Lakes Shapefile into the appropriate coordinate reference system. WatertonRePro&lt;-spTransform(shpWaterton,CRSobj = WGS84) # Fortifying the shapefile allowing it to be projected. This fortify causes the shapefile to become a data frame. shapefileWaterton&lt;-fortify(WatertonRePro) # Keeping only the years of interest both pre and post fire. (Pre-fire = 2012-2014 and Post-fire = 2018-2020) Dates&lt;-Data[which(Data$Year %in% c(&quot;2012&quot;,&quot;2013&quot;,&quot;2014&quot;,&quot;2018&quot;,&quot;2019&quot;,&quot;2020&quot;)),] # Aggregating the effort data across camera codes, season, and time-periods Aggregated&lt;-aggregate(Effort_per_week ~ Camera_Code + Season + Status, data = Dates, sum) # Changing the column name (Name) in locations to Camera_Code for the merge names(Locations)[names(Locations) == &quot;Name&quot;] &lt;- &quot;Camera_Code&quot; # Joining the location data (latitude,longitude) to the effort data Merged&lt;-merge(Aggregated,Locations, by = &quot;Camera_Code&quot;) # Sub-setting to only the required columns of data. S&lt;-Merged[,c(1:4,8:9)] # Changing the name of the &quot;effort per week&quot; column into just &quot;effort&quot; names(S)[names(S) == &quot;Effort_per_week&quot;] &lt;- &quot;Effort&quot; # Sub-setting the data into separate data frames by season and time-period PreSpring&lt;-S[which(S$Season == &quot;Spring&quot; &amp; S$Status == &quot;Prefire&quot;),] PreSummer&lt;-S[which(S$Season == &quot;Summer&quot; &amp; S$Status == &quot;Prefire&quot;),] PreAutumn&lt;-S[which(S$Season == &quot;Autumn&quot; &amp; S$Status == &quot;Prefire&quot;),] PostSpring&lt;-S[which(S$Season == &quot;Spring&quot; &amp; S$Status == &quot;Postfire&quot;),] PostSummer&lt;-S[which(S$Season == &quot;Summer&quot; &amp; S$Status == &quot;Postfire&quot;),] PostAutumn&lt;-S[which(S$Season == &quot;Autumn&quot; &amp; S$Status == &quot;Postfire&quot;),] Mapping the Data # Set a bounding box for the map. This is set to include all of Waterton plus some buffer. bbox&lt;-c(left = -114.2, bottom = 48.95, right = -113.6, top = 49.25) # Creating the maps for the spring season both pre-fire and post-fire. PreSpringEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PreSpring, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Pre-fire Spring Season Camera Effort&quot;) PostSpringEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PostSpring, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Post-fire Spring Season Camera Effort&quot;) # Set a bounding box for the map. This is set to include all of Waterton plus some buffer. bbox&lt;-c(left = -114.2, bottom = 48.95, right = -113.6, top = 49.25) # Creating the maps for the spring season both pre-fire and post-fire. PreSummerEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PreSummer, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Pre-fire Summer Season Camera Effort&quot;) PostSummerEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PostSummer, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Post-fire Summer Season Camera Effort&quot;) # Set a bounding box for the map. This is set to include all of Waterton plus some buffer. bbox&lt;-c(left = -114.2, bottom = 48.95, right = -113.6, top = 49.25) # Creating the maps for the spring season both pre-fire and post-fire. PreAutumnEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PreAutumn, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Pre-fire Autumn Season Camera Effort&quot;) PostAutumnEffort = ggmap(get_stamenmap(bbox, maptype = &quot;terrain-background&quot;, zoom = 12))+ geom_path(data = shapefileWaterton, aes(x = long, y = lat, group = group),size = 1)+ geom_point(data = PostAutumn, aes(x = Longitude, y = Latitude, size = Effort),colour = &quot;red&quot;) + ggtitle(&quot;Post-fire Autumn Season Camera Effort&quot;) Interpretation and Action It appears that there are some seasons which have low camera effort which is most likely due to a malfunctioning or non-operating camera. These differences in camera effort will be controlled for in my model with the addition of an offset predictor of survey effort (Number of Camera Operating Days). These differences in effort should not affect the results of my models. No action will be taken. "],["conduct-data-exploration.html", "3 - Conduct Data Exploration (Zuur, Ieno, and Elphick 2010) Protocol A - Outliers in the response and explanatory variables B - Homogeneity in the response variable C - Normality in the response D - Zero Trouble Y E - Collinearity in the response F - Relationships in the response and explanatory variables G - Interactions H - Independence in the response variable", " 3 - Conduct Data Exploration Before creating my first models I followed the data exploration protocol found in (Zuur, Ieno, and Elphick 2010). (Zuur, Ieno, and Elphick 2010) Protocol The 8 steps from the (Zuur, Ieno, and Elphick 2010) data exploration protocol include checking for: Outliers in the response and explanatory variables Homogeneity in the response variable Normality in the response Zero trouble in the response Collinearity in the response Relationships in the response and explanatory variables Interactions Independence in the response variable Note that some of these steps are not designed for use with categorcial variables. Preparing the Data library(ggplot2) library(ggpubr) library(lattice) library(gridExtra) library(ape) library(tidyr) library(tidyverse) library(dplyr) library(knitr) library(ncf) # Reading in the adult black bear data and the camera locality data Bear&lt;-read.csv(&quot;./Data/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Locations&lt;-read.csv(&quot;./Data/ParksCanadaCameraLocations.csv&quot;,header=TRUE,stringsAsFactors = FALSE) # Setting Season as a factor and ordering it for future plots, this will allow for plots to be ordered in spring, summer, autumn Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season &lt;- ordered(Bear$Season, levels = c(&quot;Spring&quot;, &quot;Summer&quot;, &quot;Autumn&quot;)) # Separating pre-fire and post-fire data into separate data frames Pre&lt;-Bear[which(Bear$Status == &quot;Prefire&quot;),] Post&lt;-Bear[which(Bear$Status == &quot;Postfire&quot;),] Here is a quick look at the structure of the Bear data frame str(Bear) ## &#39;data.frame&#39;: 5226 obs. of 10 variables: ## $ Camera_Code : chr &quot;H10&quot; &quot;H10&quot; &quot;H10&quot; &quot;H10&quot; ... ## $ Ordered_Week : int 217 218 219 220 221 222 223 224 225 226 ... ## $ Species : chr &quot;black&quot; &quot;black&quot; &quot;black&quot; &quot;black&quot; ... ## $ Region : Factor w/ 2 levels &quot;Burnt&quot;,&quot;Unburnt&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Lone_Adult : int 0 0 0 0 0 0 0 1 0 0 ... ## $ Effort_per_week : int 1 7 7 7 7 7 7 7 7 7 ... ## $ Season : Ord.factor w/ 3 levels &quot;Spring&quot;&lt;&quot;Summer&quot;&lt;..: 1 1 1 1 1 1 1 1 1 1 ... ## $ Status : Factor w/ 2 levels &quot;Postfire&quot;,&quot;Prefire&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Group_Size : num 1.82 2.62 2.67 1.33 2.75 ... ## $ Number_of_Groups: int 11 16 6 6 12 4 10 4 0 2 ... head(Bear) ## Camera_Code Ordered_Week Species Region Lone_Adult Effort_per_week Season ## 1 H10 217 black Burnt 0 1 Spring ## 2 H10 218 black Burnt 0 7 Spring ## 3 H10 219 black Burnt 0 7 Spring ## 4 H10 220 black Burnt 0 7 Spring ## 5 H10 221 black Burnt 0 7 Spring ## 6 H10 222 black Burnt 0 7 Spring ## Status Group_Size Number_of_Groups ## 1 Prefire 1.818182 11 ## 2 Prefire 2.625000 16 ## 3 Prefire 2.666667 6 ## 4 Prefire 1.333333 6 ## 5 Prefire 2.750000 12 ## 6 Prefire 2.500000 4 A - Outliers in the response and explanatory variables To assess for outliers I plotted both the number of weekly bear events (continuous predictor) and the number of weekly human groups (response variable) as box and whisker plots and Cleveland dot plots. # Box plot of the response variable (Number of adult black bears per week) boxplot(Bear$Lone_Adult, ylab = &quot;Number of events per week per camera&quot;, main = &quot;Weekly Number of Lone Adult Black Bear Events per Camera&quot;) # Boxplot of continuous variable (Number of human groups) boxplot(Bear$Number_of_Groups, ylab = &quot;Number of groups per week per camera&quot;, main = &quot;Weekly Number of Human Events per Camera&quot;) ggplot(Bear, aes(Lone_Adult,Camera_Code)) + geom_point(aes(color = Season), size = 2, position=position_dodge(width = 0.5)) + labs(title = &quot;Cleveland Dotplot of Weekly Lone Adult Black Bear Events per Camera&quot;, x = &quot;Number of Bear Events&quot;, y = &quot;Camera Code&quot;) ggplot(Bear, aes(Number_of_Groups,Camera_Code)) + geom_point(aes(color = Season), size = 2, position=position_dodge(width = 0.5))+ labs(title = &quot;Cleveland Dotplot of Weekly Human Events per Camera&quot;, x = &quot;Number of Human Events&quot;, y = &quot;Camera Code&quot;) Interpretation and Action There is no evidence of outliers in the above plots. I will not be implementing any changes at this stage. B - Homogeneity in the response variable In order to assess for violations in the assumption of homogeneity in the response variable I conducted conditional boxplots. Boxplots show the response variable plotted per factor level in each categorical predictor. # Response variable plotted by seasons Homogeneity1&lt;-bwplot(Lone_Adult ~ Season | Region * Status, data = Bear) Homogeneity2&lt;-bwplot(Lone_Adult ~ Season | Region, data = Bear) Homogeneity3&lt;-bwplot(Lone_Adult ~ Season | Status, data = Bear) Homogeneity4&lt;-bwplot(Lone_Adult ~ Status | Region, data = Bear) grid.arrange(Homogeneity1,Homogeneity2,Homogeneity3,Homogeneity4) Interpretation and Action It appears that the summer season and the burnt post-fire region may show violations of homogeneity. These appear to be rather small in nature and zuur et al, recommends checking for violation in homogeneity in the model residuals. No action will be taken at this time, however, we will look into this again with model residuals. C - Normality in the response As we are working with count data we expect for a Poisson or negative binomial response variable distribution. In order to evaluate the distribution of the response variable I will plot a histogram of response variable frequency. # Plotting the weekly black bear event frequency into a histogram hist(Bear$Lone_Adult,breaks=seq(-1,16,1), label = TRUE, main = &quot;Frequency Plot of Weekly Lone Black Bear Events&quot;, xlab = &quot;Number of Lone Adult Black Bear Events per Week&quot;) Interpretation and Action As anticipated, the response variable distribution appears to be either Poisson or negative binomial in nature. I will first fit the model using a Poisson distribution and will consider negative binomial if there is over dispersion present in the Poisson model. D - Zero Trouble Y In order to assess whether there is zero-inflation in the response variable I will plot a histogram of the event frequency. (Same plot as above) # Plotting the weekly black bear event frequency into a histogram hist(Bear$Lone_Adult,breaks=seq(-1,16,1), label = TRUE, main = &quot;Frequency Plot of Weekly Lone Black Bear Events&quot;, xlab = &quot;Number of Lone Adult Black Bear Events per Week&quot;) Interpretation and Action It appears that I may need to consider the use of a zero-inflated model. I will first fit a Poisson model without a zero-inflation term and formally test for zero-inflation in the fit model. E - Collinearity in the response Due to my model only containing one continuous predictor I did not test for collinearity in predictors. F - Relationships in the response and explanatory variables In order to evaluate if there are any relationships between predictors and the response variable I plotted all predictos against the response variable. With most of my predictors being categorical these plots will be more informative in finding outliers than relationships between predictors and response. It is suggested that in order to explore the relationships we should use multi-panel scatter plots and conditional boxplots. Relation1&lt;-ggplot(data = Bear, aes(x = Status, y = Lone_Adult)) + geom_boxplot() Relation2&lt;-ggplot(data = Bear, aes(x = Region, y = Lone_Adult)) + geom_boxplot() Relation3&lt;-ggplot(data = Bear, aes(x = Season, y = Lone_Adult)) + geom_boxplot() Relation4&lt;-ggplot(data = Bear, aes(x = Number_of_Groups, y = Lone_Adult)) + geom_point() + geom_smooth(method=&#39;lm&#39;) ggarrange(Relation1,Relation2,Relation3,Relation4) ## `geom_smooth()` using formula &#39;y ~ x&#39; Interpretation and Action These plots do not suggest any observable issues when plotting residuals against the predictors. The positive relationship between the number of bear events and the number of human groups is unexpected and should be explored further. There appears to be no observable outliers in the categorical predictors. Overall, there are not any alarming trends or points in the plots above. G - Interactions In order to evaluate the possiblity of interacting effects between predictors I created coplots and conditional boxplots (boxplots for categorical predictors only). coplot(Lone_Adult~Number_of_Groups|Season * Region,data = Bear, xlab = &quot;Number_of_Groups&quot;, panel = function(x, y, ...) { tmp &lt;- lm(y ~ x, na.action = na.omit) abline(lm(y ~ x), col = &quot;blue&quot;) points(x, y) }) coplot(Lone_Adult~Number_of_Groups|Season * Status,data = Bear, xlab = &quot;Number_of_Groups&quot;, panel = function(x, y, ...) { tmp &lt;- lm(y ~ x, na.action = na.omit) abline(lm(y ~ x), col = &quot;blue&quot;) points(x, y) }) coplot(Lone_Adult~Number_of_Groups|Region * Status,data = Bear, xlab = &quot;Number_of_Groups&quot;, panel = function(x, y, ...) { tmp &lt;- lm(y ~ x, na.action = na.omit) abline(lm(y ~ x), col = &quot;blue&quot;) points(x, y) }) Interaction4&lt;-ggplot(data = Bear, aes(x = Status, y = Lone_Adult)) + geom_boxplot() + geom_smooth(method=&quot;lm&quot;,aes(group=1)) Interaction4 + facet_grid(Season ~ Region) ## `geom_smooth()` using formula &#39;y ~ x&#39; Interpretation and Action It appears that there are some interactions to keep in mind. It seems that there is a noticeable interaction of season with all other variables being considered. There may also be an interaction of region and time-period but it is difficult to interpret in the graphs due to the large amount of zeros. Overall, there does not appear to be any issues in the data in regards to interactions, during model fit these interactions will be explored further. H - Independence in the response variable In order to check for spatial autocorrelation in the raw data I plotted a spline correlogram using distance data and the response variable. # Spatial Autocorrelation using ncf colnames(Locations)[which(names(Locations) == &quot;Name&quot;)] &lt;- &quot;Camera_Code&quot; M&lt;-merge(Bear,Locations[,c(&quot;Camera_Code&quot;,&quot;Latitude&quot;,&quot;Longitude&quot;)], by = &quot;Camera_Code&quot;) Agged&lt;-aggregate(Lone_Adult~Camera_Code+Longitude+Latitude, data = M, sum) SpatialAutocorrelation &lt;- spline.correlog(Agged$Longitude,Agged$Latitude,Agged$Lone_Adult) Interpretation and Action There appears to be an effect of spatial autocorrelation in the raw data, although it doesnt appear to be severe in nature. Despite this evidence of spatial autocorrelation in the raw data I believe that my final model will address this issue and I will further test the effect of spatial autocorrelation in the residuals of my model. References "],["identify-the-dependency-structure-in-the-data.html", "4 - Identify the Dependency Structure in the Data", " 4 - Identify the Dependency Structure in the Data We need to identify possible issues of pseudo-replication in the data. This data contains multiple observations per camera per week across both years and seasons. We will therefore fit a generalized linear mixed effects model with the term Camera ID specified as a random effect. This term will account for any possible pseudo-replication which would arise from having multiple sampling events for each camera. "],["present-the-statistical-model.html", "5 - Present the Statistical Model Response Variable Predictors Random Term", " 5 - Present the Statistical Model Response Variable In order to measure bear use intensity I will be using the number of bear events per week as my response variable. In order to calculate this I have binned all lone adult black bear events per week of the year for each year in my study. A reminder that that an event is defined as a capture of a black bear separated by 10 or more minutes from any other black bear events and that if two captures occur within 10 minutes it is considered one event. Response - Number of black bear events per week Predictors Categorical - Season (Spring/Summer/Autumn) - Status (Pre-fire/Post-fire) - Region (Burnt/Unburnt) Continuous - Number of Human Groups Offset - The log transformed number of active camera days per week The log transformation of offsets are required for generalized regressions with log link functions. Random Term As discussed in the previous section we will be using the term Camera ID as a random term to account for multiple sampling at a location across seasons and years. This will account for this dependency and eliminate worry of pseudo-replication. Random Effect - Camera ID "],["model-fit.html", "6 - Model Fit Choosing a Model Structure Model Selection Final Selected Model", " 6 - Model Fit Preparing the Data library(glmmTMB) library(lme4) library(DHARMa) library(ggplot2) library(performance) library(see) library(patchwork) library(MASS) library(lmtest) library(car) library(ggeffects) library(effects) setwd(&quot;D:/DataAndAnalysis&quot;) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Datasets/FinalDatasets/ForExploration/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) # Setting the predictors as factors for later functions Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Choosing a Model Structure In order to choose the appropriate model structure I followed instructions from (Zuur et al. 2009). I first fit a Poisson model to access zero-inflation and over-dispersion. Models were fit using the full suite of predictors and their interactions which will be called the Global Model from here on out. FullModelPoisson&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + Season:Region + Region:Status + Season:Status:Number_of_Groups + Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + Season:Region:Status + Season:Region:Status:Number_of_Groups + offset(Effort_per_week) + (1|Camera_Code), data = Bear, na.action = na.pass, family = poisson()) #Check dispersion check_overdispersion(FullModelPoisson) ## # Overdispersion test ## ## dispersion ratio = 4.067 ## Pearson&#39;s Chi-Squared = 21154.005 ## p-value = &lt; 0.001 ## Overdispersion detected. #Check zero inflation check_zeroinflation(FullModelPoisson) ## # Check for zero-inflation ## ## Observed zeros: 3903 ## Predicted zeros: 3619 ## Ratio: 0.93 ## Model is underfitting zeros (probable zero-inflation). Interpretation and Action With evidence of both overdispersion and zero-inflation my next step was to fit both a zero-inflated Poisson model and zero-inflated negative binomial model. I conducted a likelihood ratio test between the two zero-inflated global models using the package lmtest (Zeileis and Hothorn 2002) as recommended by (Zuur et al. 2009). By conducting a likelihood ratio test between the two zero-inflated models we are determining whether the overdispersion comes from the zeros (in which case a zero-inflated Poisson is appropriate) or if it is not caused by the zeros in which case the negative binomial is most appropriate. #Creating a Zero-inflated Poisson global model ZiFullModelPoisson&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + Season:Region + Region:Status + Season:Status:Number_of_Groups + Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + Season:Region:Status + Season:Region:Status:Number_of_Groups + offset(Effort_per_week) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = poisson()) #Creating a zero-inflated negative binomial global model ZiFullModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + Season:Region + Region:Status + Season:Status:Number_of_Groups + Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + Season:Region:Status + Season:Region:Status:Number_of_Groups + offset(Effort_per_week) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1()) #Running a likelihood ratio test between the two zero inflated models lrtest(ZiFullModelPoisson,ZiFullModel) ## Likelihood ratio test ## ## Model 1: Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + ## Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + ## Season:Region + Region:Status + Season:Status:Number_of_Groups + ## Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + ## Season:Region:Status + Season:Region:Status:Number_of_Groups + ## offset(Effort_per_week) + (1 | Camera_Code) ## Model 2: Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + ## Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + ## Season:Region + Region:Status + Season:Status:Number_of_Groups + ## Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + ## Season:Region:Status + Season:Region:Status:Number_of_Groups + ## offset(Effort_per_week) + (1 | Camera_Code) ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 28 -4206.3 ## 2 29 -4114.8 1 182.98 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpretation and Action The likelihood ratio test shows that the variance structure of the Poisson model and the negative binomial model differs significantly suggesting that the dispersion is not caused by the zeros in the data. In the case of a significant likelihood ratio test Zuure et al.Â 2009 states that the zero-inflated negative binomial model should be used. Therefore, moving forward I will be using the zero-inflated negative binomial model for model selection. Model Selection In order to fit the appropriate model I used information from (Zuur et al. 2009) to complete backwards step-wise selection. When conducting backwards step wise selection I first started with a global model which contained all predictors of interest, and their interactions. I proceeded to drop non-significant terms from this model one at a time using the drop1 function. I dropped these terms until all terms remaining in the model were deemed to be significant at the 5% level. Below I have included a portion of my step wise backward model selection process. ##Starting the dropping of variables for model selection. #Drop test from the ZiFullModel drop1.test &lt;- drop1(ZiFullModel, test=&quot;Chisq&quot;) # Shows that Region/Season/Status/Human Groups is not significant. drop1.test[rev(order(drop1.test$&quot;Pr(&gt;Chi)&quot;)),] ## Single term deletions ## ## Model: ## Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + ## Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + ## Season:Region + Region:Status + Season:Status:Number_of_Groups + ## Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + ## Season:Region:Status + Season:Region:Status:Number_of_Groups + ## offset(Effort_per_week) + (1 | Camera_Code) ## Df AIC LRT Pr(&gt;Chi) ## &lt;none&gt; 8287.7 ## Region:Season:Status:Number_of_Groups 2 8284.1 0.45524 0.7964 #Specifying new model with interaction term Region/Season/Status/Human Groups dropped Fit1&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + Season:Region + Region:Status + Season:Status:Number_of_Groups + Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + Season:Region:Status + offset(Effort_per_week) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1()) #Second drop test drop2.test &lt;- drop1(Fit1, test=&quot;Chisq&quot;) # Shows that Region/Status/Number of Groups is not significant drop2.test[rev(order(drop2.test$&quot;Pr(&gt;Chi)&quot;)),] ## Single term deletions ## ## Model: ## Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + ## Number_of_Groups:Status + Number_of_Groups:Region + Season:Status + ## Season:Region + Region:Status + Season:Status:Number_of_Groups + ## Season:Region:Number_of_Groups + Region:Status:Number_of_Groups + ## Season:Region:Status + offset(Effort_per_week) + (1 | Camera_Code) ## Df AIC LRT Pr(&gt;Chi) ## &lt;none&gt; 8284.1 ## Region:Status:Number_of_Groups 1 8282.3 0.1457 0.70263 ## Season:Status:Number_of_Groups 2 8282.2 2.0517 0.35850 ## Region:Season:Number_of_Groups 2 8282.6 2.4716 0.29060 ## Region:Season:Status 2 8289.1 8.9495 0.01139 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Final Selected Model Below is the final model after model selection. All terms and interactions in this model are significant at the 5% level. FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Season:Status + Season:Region + Region:Status + Season:Region:Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) References "],["model-diagnostics.html", "7 - Model Diagnostics DHARMa Residual Package Outliers and Normality Testing for Over and Under Dispersion Zero-Inflation Test Testing Within Group Uniformity and Between Group Homogeneity", " 7 - Model Diagnostics DHARMa Residual Package In order to validate my fitted model I needed to conduct diagnostic tests on the model residuals as suggested in step 7 Validate the Model by (Zuur and Ieno 2016). It is common practice to use Pearson and deviance residuals when evaluating various regression methods. However, these residuals are not recommended in non-normally distributed model validation because they may not follow a normal distribution making the resulting plots difficult to interpret and possibly incorrect (Dunn and Smyth 1996; Feng, Li, and Sadeghpour 2020; Bai et al. 2021). It is suggested that the most efficient and reliable method for model validation is using randomized quantile residuals (RQR) which will follow a normal distribution when applied to a correct count regression model (Dunn and Smyth 1996; Feng, Li, and Sadeghpour 2020). RQRs are also recommended when modelling non-normal discrete response variables (Sadeghpour, 2016). I used the R package DHARMa (Hartig 2022) to calculate and plot RQRs for my final selected models. The DHARMa package simulates new response data from our fitted models and calculates scaled RQRs using this simulated data (Hartig 2022). Preparing the Data library(glmmTMB) library(lme4) library(DHARMa) library(ggplot2) library(performance) library(see) library(patchwork) library(MASS) library(lmtest) library(car) library(ggeffects) library(effects) library(coefplot) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Data/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Season*Status + Season*Region + Region*Status + Season*Region*Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) Outliers and Normality In order to evaluate for outliers or deviation from normality in the residuals I plotted the residuals in a QQ plot, residual plot, and outlier plot. QQ and Residual Plot If there are no observable issues then in the QQ plot (left) we expect to see the residuals fall along the red diagonal line. If the points deviate from this than we can infer that there may be over/under dispersion or non-normal patterns in the residuals. On the residual plot (right) we are looking for the red line to be around the 0.5 mark and no observable pattern to the residuals. #Creating the simulated residuals from the final fitted model. SimulationOutput1&lt;-simulateResiduals(fittedModel = FinalModel,n = 10000) plot(SimulationOutput1) Interpretation and Action It appears that there are no significant issues with the residuals of this fitted model. Looking at the QQ plot there are no signs of over-dispersion or under-dispersion or issues regarding normality. The residual plot does not reveal a pattern in the RQR residuals and in fact the residuals seem to lie quite well along the 0.50 mark. No action is required. Outlier Plot and Test This outlier plot and test is being conducted to further confirm the absence of outlying residuals. If there are no observable issues with the residuals than we would except to see a very small number of outliers in the histogram (red bar). There will be some number of outliers however due to the numerous simulations and bootstrapping. This outlier test is being conducted with a bootstrap method and a bootstrap value of 1000 (Hartig, n.d.). testOutliers(SimulationOutput1, type = &quot;bootstrap&quot;,nBoot = 1000) Interpretation and Action The plot and test above suggest that there is no noticeable issues regarding outlying residuals in the model. Therefore I will not take any action. Testing for Over and Under Dispersion In order to confirm that there is not either under or over dispersion in the residuals I created a histogram which illustrates the frequency of dispersion across the numerous DHARMa simulations. We expect the red vertical line on the plot to occur somewhere in the middle of the histogram. If the red line occurred at the extreme of either end of the distribution we would expect an issue with over/under dispersion in the model. testDispersion(SimulationOutput1) Interpretation and Action There does not appear to be any observable issues with over dispersion or under dispersion in the model. No action is required. Zero-Inflation Test In order to confirm that there is not zero-inflation in the residuals I created a histogram which illustrates the frequency of the number of zeros occurring across the numerous DHARMa simulations. We expect the red vertical line on the plot to occur somewhere in the middle of the histogram. If the red line occurred at the extreme of either end of the distribution we would expect an issue with zero-inflation in the model. testZeroInflation(SimulationOutput1) Interpretation and Action There does not appear to be any observable issues with zero-inflation in the model. No action will be taken. Testing Within Group Uniformity and Between Group Homogeneity In order to test whether there are violations of within group uniformity or between group homogeneity residuals were plotted by each categorical predictor. If we see a violation in either assumption the box-whisker plot will become red. I also plotted the continous predictors and if there was an issue in these plots we would see patterns within the residual plots. testCategorical(SimulationOutput1,catPred = Bear$Season) testCategorical(SimulationOutput1,catPred = Bear$Status) testCategorical(SimulationOutput1,catPred = Bear$Region) GroupsResidualPlot&lt;-plotResiduals(SimulationOutput1,Bear$Number_of_Groups) SizeResidualPlot&lt;-plotResiduals(SimulationOutput1,Bear$Group_Size) Interpretation and Action There does not appear to be any issues in outliers when plotted against all predictors included and not included in the model. References "],["interpret-and-present-the-numerical-output-of-the-model.html", "8 - Interpret and Present the Numerical Output of the Model The Model Summary Estimated Marginal Means Interpreting the interaction effect of Season:Number of Groups Effect Size Joint Test Contrasting all other included interactions", " 8 - Interpret and Present the Numerical Output of the Model Preparing the Data library(glmmTMB) library(ggplot2) library(car) library(ggeffects) library(effects) library(broom) library(broom.mixed) library(emmeans) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Data/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) # Designating the categorical predictors as factors which will allow us to order the factor levels within the model summary output Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season&lt;- factor(Bear$Season,levels = c(&quot;Spring&quot;,&quot;Summer&quot;,&quot;Autumn&quot;)) Bear$Status&lt;-relevel(Bear$Status,&quot;Prefire&quot;) Bear$Region&lt;-relevel(Bear$Region,&quot;Unburnt&quot;) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Season:Status + Season:Region + Region:Status + Season:Region:Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) The Model Summary options(width = 100) summary(FinalModel) ## Family: nbinom1 ( log ) ## Formula: ## Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + ## Season:Status + Season:Region + Region:Status + Season:Region:Status + ## offset(log(Effort_per_week)) + (1 | Camera_Code) ## Zero inflation: ~Season ## Data: Bear ## ## AIC BIC logLik deviance df.resid ## 8177.5 8308.7 -4068.8 8137.5 5206 ## ## Random effects: ## ## Conditional model: ## Groups Name Variance Std.Dev. ## Camera_Code (Intercept) 0.8119 0.9011 ## Number of obs: 5226, groups: Camera_Code, 26 ## ## Dispersion parameter for nbinom1 family (): 0.564 ## ## Conditional model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.501708 0.297650 -8.405 &lt; 2e-16 *** ## RegionBurnt -0.780231 0.401609 -1.943 0.052044 . ## SeasonSummer 0.509452 0.167306 3.045 0.002327 ** ## SeasonAutumn -0.835532 0.230132 -3.631 0.000283 *** ## StatusPostfire -0.468390 0.177219 -2.643 0.008217 ** ## Number_of_Groups 0.022201 0.006280 3.535 0.000408 *** ## SeasonSummer:Number_of_Groups -0.024291 0.006182 -3.930 8.51e-05 *** ## SeasonAutumn:Number_of_Groups -0.020087 0.006850 -2.932 0.003363 ** ## SeasonSummer:StatusPostfire 0.178515 0.194352 0.919 0.358350 ## SeasonAutumn:StatusPostfire 0.447061 0.258648 1.728 0.083907 . ## RegionBurnt:SeasonSummer 0.742372 0.199203 3.727 0.000194 *** ## RegionBurnt:SeasonAutumn 1.113030 0.253152 4.397 1.10e-05 *** ## RegionBurnt:StatusPostfire 0.382298 0.264329 1.446 0.148094 ## RegionBurnt:SeasonSummer:StatusPostfire -0.660895 0.288971 -2.287 0.022192 * ## RegionBurnt:SeasonAutumn:StatusPostfire -0.957644 0.384019 -2.494 0.012640 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Zero-inflation model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.1583 0.1883 0.841 0.4003 ## SeasonSummer -2.7365 0.3748 -7.301 2.86e-13 *** ## SeasonAutumn -0.7621 0.3535 -2.156 0.0311 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This summary is messy and difficult to interpret. Instead we will conduct post-hoc testing using the package emmaeans (Lenth 2021) to determine the effect of the interaction terms Region:Status:Season and human groups:season. Estimated Marginal Means Marginal means are values which are taken from statistical models and they represent the mean of the response variable for each level of categorical predictor variable. Due to the fact that these marginal means are taken from the statistical model and not the data itself they will most likely differ from arithmetic means of the data. More information can be found here https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html Creating the Estimated Marginal Means Not back transformed # Creating a emmeans object summary for the region:status interaction in each season. emm1&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season) summary(emm1) ## Season = Spring: ## Region Status emmean SE df lower.CL upper.CL ## Unburnt Prefire -0.4124 0.293 5206 -0.987 0.162 ## Burnt Prefire -1.1927 0.297 5206 -1.776 -0.610 ## Unburnt Postfire -0.8808 0.296 5206 -1.460 -0.301 ## Burnt Postfire -1.2788 0.299 5206 -1.864 -0.693 ## ## Season = Summer: ## Region Status emmean SE df lower.CL upper.CL ## Unburnt Prefire -0.0838 0.258 5206 -0.590 0.423 ## Burnt Prefire -0.1216 0.258 5206 -0.628 0.385 ## Unburnt Postfire -0.3736 0.260 5206 -0.883 0.136 ## Burnt Postfire -0.6901 0.262 5206 -1.204 -0.176 ## ## Season = Autumn: ## Region Status emmean SE df lower.CL upper.CL ## Unburnt Prefire -1.3975 0.304 5206 -1.994 -0.801 ## Burnt Prefire -1.0647 0.302 5206 -1.656 -0.473 ## Unburnt Postfire -1.4188 0.306 5206 -2.019 -0.818 ## Burnt Postfire -1.6613 0.328 5206 -2.304 -1.018 ## ## Results are given on the log (not the response) scale. ## Confidence level used: 0.95 The above output shows the emmeans as produced on the link scale, therefore these values are log-transformed. Back transformed # Creating a emmeans object which contrasts the response variable values of region and status for each season. This represents the BACKTRANSFORMED results. emm3&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season, type = &quot;response&quot;) Z&lt;-contrast(regrid(emm3), method = &quot;pairwise&quot;) summary(emm3) ## Season = Spring: ## Region Status response SE df lower.CL upper.CL ## Unburnt Prefire 0.662 0.1939 5206 0.3729 1.175 ## Burnt Prefire 0.303 0.0902 5206 0.1694 0.543 ## Unburnt Postfire 0.414 0.1225 5206 0.2322 0.740 ## Burnt Postfire 0.278 0.0831 5206 0.1550 0.500 ## ## Season = Summer: ## Region Status response SE df lower.CL upper.CL ## Unburnt Prefire 0.920 0.2377 5206 0.5541 1.526 ## Burnt Prefire 0.885 0.2289 5206 0.5335 1.470 ## Unburnt Postfire 0.688 0.1788 5206 0.4136 1.145 ## Burnt Postfire 0.502 0.1316 5206 0.2999 0.839 ## ## Season = Autumn: ## Region Status response SE df lower.CL upper.CL ## Unburnt Prefire 0.247 0.0752 5206 0.1362 0.449 ## Burnt Prefire 0.345 0.1040 5206 0.1909 0.623 ## Unburnt Postfire 0.242 0.0741 5206 0.1328 0.441 ## Burnt Postfire 0.190 0.0623 5206 0.0998 0.361 ## ## Confidence level used: 0.95 ## Intervals are back-transformed from the log scale The above output shows the emmeans as produced on the resoonse scale, therefore these values have been back transformed from the log scale. Contrasting the Three-way Interaction of Region:Status:Season # Presenting the contrasts with 95% confidence intervals emm1&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season) X&lt;-contrast(emm1, method = &quot;pairwise&quot;) confint(X) ## Season = Spring: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.7802 0.4016 5206 -0.2518 1.812 ## Unburnt Prefire - Unburnt Postfire 0.4684 0.1772 5206 0.0130 0.924 ## Unburnt Prefire - Burnt Postfire 0.8663 0.4025 5206 -0.1680 1.901 ## Burnt Prefire - Unburnt Postfire -0.3118 0.4037 5206 -1.3494 0.726 ## Burnt Prefire - Burnt Postfire 0.0861 0.1950 5206 -0.4149 0.587 ## Unburnt Postfire - Burnt Postfire 0.3979 0.4052 5206 -0.6433 1.439 ## ## Season = Summer: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.0379 0.3641 5206 -0.8977 0.973 ## Unburnt Prefire - Unburnt Postfire 0.2899 0.0797 5206 0.0850 0.495 ## Unburnt Prefire - Burnt Postfire 0.6063 0.3665 5206 -0.3354 1.548 ## Burnt Prefire - Unburnt Postfire 0.2520 0.3648 5206 -0.6855 1.189 ## Burnt Prefire - Burnt Postfire 0.5685 0.0859 5206 0.3478 0.789 ## Unburnt Postfire - Burnt Postfire 0.3165 0.3673 5206 -0.6275 1.260 ## ## Season = Autumn: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire -0.3328 0.3949 5206 -1.3476 0.682 ## Unburnt Prefire - Unburnt Postfire 0.0213 0.1886 5206 -0.4633 0.506 ## Unburnt Prefire - Burnt Postfire 0.2639 0.4145 5206 -0.8014 1.329 ## Burnt Prefire - Unburnt Postfire 0.3541 0.3990 5206 -0.6712 1.379 ## Burnt Prefire - Burnt Postfire 0.5967 0.2053 5206 0.0691 1.124 ## Unburnt Postfire - Burnt Postfire 0.2425 0.4185 5206 -0.8329 1.318 ## ## Results are given on the log (not the response) scale. ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates # Presenting the results with 95% confidence intervals emm3&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season, type = &quot;response&quot;) Z&lt;-contrast(regrid(emm3), method = &quot;pairwise&quot;) confint(Z) ## Season = Spring: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.35863 0.2077 5206 -0.17514 0.892 ## Unburnt Prefire - Unburnt Postfire 0.24760 0.1171 5206 -0.05333 0.549 ## Unburnt Prefire - Burnt Postfire 0.38366 0.2052 5206 -0.14370 0.911 ## Burnt Prefire - Unburnt Postfire -0.11103 0.1468 5206 -0.48817 0.266 ## Burnt Prefire - Burnt Postfire 0.02503 0.0571 5206 -0.12171 0.172 ## Unburnt Postfire - Burnt Postfire 0.13606 0.1431 5206 -0.23175 0.504 ## ## Season = Summer: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.03417 0.3286 5206 -0.81040 0.879 ## Unburnt Prefire - Unburnt Postfire 0.23142 0.0866 5206 0.00897 0.454 ## Unburnt Prefire - Burnt Postfire 0.41812 0.2706 5206 -0.27718 1.113 ## Burnt Prefire - Unburnt Postfire 0.19726 0.2891 5206 -0.54581 0.940 ## Burnt Prefire - Burnt Postfire 0.38395 0.1129 5206 0.09394 0.674 ## Unburnt Postfire - Burnt Postfire 0.18670 0.2209 5206 -0.38098 0.754 ## ## Season = Autumn: ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire -0.09762 0.1188 5206 -0.40304 0.208 ## Unburnt Prefire - Unburnt Postfire 0.00522 0.0461 5206 -0.11335 0.124 ## Unburnt Prefire - Burnt Postfire 0.05734 0.0906 5206 -0.17547 0.290 ## Burnt Prefire - Unburnt Postfire 0.10284 0.1191 5206 -0.20315 0.409 ## Burnt Prefire - Burnt Postfire 0.15496 0.0667 5206 -0.01653 0.326 ## Unburnt Postfire - Burnt Postfire 0.05212 0.0904 5206 -0.18010 0.284 ## ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates Interpretation In the above table we can see that the number of significant estimate values differ between the log transformed and back transformed estimated marginal means. In the log transformed marginal mean contrasts we see significant estimates in the spring for the unburnt region, in the summer for both regions and in autumn for the burnt region. However, in the back transformed contrasts we only see significant estimates in the summer in both unburnt and burnt regions. In all the above cases the number of bear events has decreased in the postfire landscape as evident by the postivie estimate value. The postive estimate shows a decrease in bear events becuase the contrast is compating the unburnt region to the burnt region. Interpreting the interaction effect of Season:Number of Groups Using the emtrends function from the (Lenth 2021) function we can calculate the effect of the number of human groups on bear activity for each season. emtrends(FinalModel, pairwise ~ Season, var = &quot;Number_of_Groups&quot;) ## $emtrends ## Season Number_of_Groups.trend SE df lower.CL upper.CL ## Spring 0.02220 0.00628 5206 0.00989 0.034512 ## Summer -0.00209 0.00114 5206 -0.00433 0.000147 ## Autumn 0.00211 0.00317 5206 -0.00411 0.008335 ## ## Results are averaged over the levels of: Region, Status ## Confidence level used: 0.95 ## ## $contrasts ## contrast estimate SE df t.ratio p.value ## Spring - Summer 0.0243 0.00618 5206 3.930 0.0003 ## Spring - Autumn 0.0201 0.00685 5206 2.932 0.0095 ## Summer - Autumn -0.0042 0.00323 5206 -1.301 0.3947 ## ## Results are averaged over the levels of: Region, Status ## P value adjustment: tukey method for comparing a family of 3 estimates Interpretation We can see that both spring and autumn have positive relationships between the number of human groups using a trail and the number of bears using the trail. Summer meanwhile shows a negative trend which is much more expected. Looking at the confidence intervals the spring season is the only season which shows a significant relationship between human groups and bear groups. Meanwhile if we look at the contrasts we can see that the effect seen in spring is significantly different than the effects seen in both summer and autumn while the contrast between autumn and summer appears to not be significant. Effect Size The following code calculates the effect sizes of each contrast using the function eff_size from the package (Lenth 2021). EFF1&lt;-eff_size(emm3, sigma = sigma(FinalModel), edf = Inf, method = &quot;pairwise&quot;) summary(EFF1) ## Season = Spring: ## contrast effect.size SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 1.3823 0.712 5206 -0.0126 2.777 ## Unburnt Prefire - Unburnt Postfire 0.8298 0.314 5206 0.2143 1.445 ## Unburnt Prefire - Burnt Postfire 1.5349 0.713 5206 0.1369 2.933 ## Burnt Prefire - Unburnt Postfire -0.5525 0.715 5206 -1.9547 0.850 ## Burnt Prefire - Burnt Postfire 0.1525 0.345 5206 -0.5246 0.830 ## Unburnt Postfire - Burnt Postfire 0.7050 0.718 5206 -0.7022 2.112 ## ## Season = Summer: ## contrast effect.size SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.0671 0.645 5206 -1.1974 1.332 ## Unburnt Prefire - Unburnt Postfire 0.5136 0.141 5206 0.2367 0.790 ## Unburnt Prefire - Burnt Postfire 1.0742 0.649 5206 -0.1986 2.347 ## Burnt Prefire - Unburnt Postfire 0.4465 0.646 5206 -0.8205 1.714 ## Burnt Prefire - Burnt Postfire 1.0072 0.152 5206 0.7089 1.305 ## Unburnt Postfire - Burnt Postfire 0.5607 0.651 5206 -0.7151 1.836 ## ## Season = Autumn: ## contrast effect.size SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire -0.5896 0.700 5206 -1.9612 0.782 ## Unburnt Prefire - Unburnt Postfire 0.0378 0.334 5206 -0.6172 0.693 ## Unburnt Prefire - Burnt Postfire 0.4675 0.734 5206 -0.9723 1.907 ## Burnt Prefire - Unburnt Postfire 0.6274 0.707 5206 -0.7584 2.013 ## Burnt Prefire - Burnt Postfire 1.0571 0.364 5206 0.3441 1.770 ## Unburnt Postfire - Burnt Postfire 0.4297 0.741 5206 -1.0238 1.883 ## ## sigma used for effect sizes: 0.5644 ## Confidence level used: 0.95 Interpretation I am unsure how to interpret the results from the effect size function at this time. I had originally thought that by back transforming my estimated marginal means (as above) I had received my effect sizes, however, these differ from the effect size function found above. I assume that these values should be the same however that may be incorrect and I will look into that further. Joint Test The joint test in the emmeans package is similar in nature to a Type-III ANOVA. The main effects are calculated from families of contrasts and the interaction effects are interaction contrasts. (Lenth 2021) Joint test conducted on all predictors and interactions present in the model. joint_tests(FinalModel) ## model term df1 df2 F.ratio p.value ## Region 1 5206 0.440 0.5071 ## Season 2 5206 6.036 0.0024 ## Status 1 5206 25.607 &lt;.0001 ## Number_of_Groups 1 5206 8.687 0.0032 ## Region:Season 2 5206 5.663 0.0035 ## Region:Status 1 5206 1.374 0.2413 ## Season:Status 2 5206 0.764 0.4659 ## Season:Number_of_Groups 2 5206 8.361 0.0002 ## Region:Season:Status 2 5206 3.537 0.0292 0.0.1 Interpretation As I understand it this ANOVA like table tests for the significance of each effect in the model. For example the term region its self is not a significant predictor of bear events while status is a significant predictor. Ultimately in this table the three way interaction of Region:Season:Status and two way interaction of Season:Number_of_Groups are the most important rows to look at. Joint test conducted on all predictors and interactions present in the model using the predictor of season to group results. joint_tests(FinalModel, by = &quot;Season&quot;) ## Season = Spring: ## model term df1 df2 F.ratio p.value ## Region 1 5206 2.389 0.1222 ## Status 1 5206 4.458 0.0348 ## Number_of_Groups 1 5206 12.497 0.0004 ## Region:Status 1 5206 2.092 0.1482 ## ## Season = Summer: ## model term df1 df2 F.ratio p.value ## Region 1 5206 0.241 0.6236 ## Status 1 5206 53.967 &lt;.0001 ## Number_of_Groups 1 5206 3.355 0.0671 ## Region:Status 1 5206 5.623 0.0178 ## ## Season = Autumn: ## model term df1 df2 F.ratio p.value ## Region 1 5206 0.014 0.9060 ## Status 1 5206 4.919 0.0266 ## Number_of_Groups 1 5206 0.444 0.5053 ## Region:Status 1 5206 4.257 0.0391 0.0.2 Interpretation This table is more insightful as it breaks down the significance of each predictor and the two way interaction of region:status (the fire effect) for each season. We can see that the fire effect is not significant in the spring season but is significant in both the summer and autumn seasons. We can also see that status (time-period) is a significant predictor in all seasons. Number of human groups is significant in spring and summer but not autumn. Contrasting all other included interactions RegionSeason&lt;-emmeans(FinalModel,spec = ~ Region:Season, type = &quot;response&quot;) RSea&lt;-contrast(regrid(RegionSeason), method = &quot;pairwise&quot;) confint(RSea) ## contrast estimate SE df lower.CL upper.CL ## Unburnt Spring - Burnt Spring 0.2332 0.1623 5206 -0.22958 0.6959 ## Unburnt Spring - Unburnt Summer -0.2718 0.1006 5206 -0.55866 0.0152 ## Unburnt Spring - Burnt Summer -0.1426 0.2251 5206 -0.78422 0.4990 ## Unburnt Spring - Unburnt Autumn 0.2792 0.1012 5206 -0.00925 0.5677 ## Unburnt Spring - Burnt Autumn 0.2679 0.1648 5206 -0.20188 0.7377 ## Burnt Spring - Unburnt Summer -0.5049 0.2193 5206 -1.12998 0.1201 ## Burnt Spring - Burnt Summer -0.3758 0.1060 5206 -0.67796 -0.0736 ## Burnt Spring - Unburnt Autumn 0.0460 0.1082 5206 -0.26240 0.3545 ## Burnt Spring - Burnt Autumn 0.0347 0.0552 5206 -0.12262 0.1921 ## Unburnt Summer - Burnt Summer 0.1292 0.2648 5206 -0.62576 0.8841 ## Unburnt Summer - Unburnt Autumn 0.5510 0.1478 5206 0.12974 0.9722 ## Unburnt Summer - Burnt Autumn 0.5397 0.2174 5206 -0.08009 1.1594 ## Burnt Summer - Unburnt Autumn 0.4218 0.1853 5206 -0.10648 0.9501 ## Burnt Summer - Burnt Autumn 0.4105 0.1163 5206 0.07893 0.7421 ## Unburnt Autumn - Burnt Autumn -0.0113 0.0958 5206 -0.28426 0.2617 ## ## Results are averaged over the levels of: Status ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 6 estimates StatusSeason&lt;-emmeans(FinalModel,spec = ~ Status:Season, type = &quot;response&quot;) StatSea&lt;-contrast(regrid(StatusSeason), method = &quot;pairwise&quot;) confint(StatSea) ## contrast estimate SE df lower.CL upper.CL ## Prefire Spring - Postfire Spring 0.1085 0.0562 5206 -0.0517 0.2687 ## Prefire Spring - Prefire Summer -0.4542 0.1042 5206 -0.7512 -0.1573 ## Prefire Spring - Postfire Summer -0.1393 0.0666 5206 -0.3292 0.0506 ## Prefire Spring - Prefire Autumn 0.1562 0.0737 5206 -0.0538 0.3662 ## Prefire Spring - Postfire Autumn 0.2338 0.0764 5206 0.0160 0.4516 ## Postfire Spring - Prefire Summer -0.5627 0.1150 5206 -0.8906 -0.2348 ## Postfire Spring - Postfire Summer -0.2478 0.0677 5206 -0.4409 -0.0548 ## Postfire Spring - Prefire Autumn 0.0477 0.0596 5206 -0.1222 0.2175 ## Postfire Spring - Postfire Autumn 0.1253 0.0583 5206 -0.0408 0.2914 ## Prefire Summer - Postfire Summer 0.3149 0.0708 5206 0.1131 0.5167 ## Prefire Summer - Prefire Autumn 0.6104 0.1232 5206 0.2592 0.9617 ## Prefire Summer - Postfire Autumn 0.6880 0.1333 5206 0.3080 1.0681 ## Postfire Summer - Prefire Autumn 0.2955 0.0742 5206 0.0841 0.5069 ## Postfire Summer - Postfire Autumn 0.3731 0.0807 5206 0.1430 0.6033 ## Prefire Autumn - Postfire Autumn 0.0776 0.0383 5206 -0.0314 0.1867 ## ## Results are averaged over the levels of: Region ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 6 estimates RegionStatus&lt;-emmeans(FinalModel,spec = ~ Region:Status, type = &quot;response&quot;) RStat&lt;-contrast(regrid(RegionStatus), method = &quot;pairwise&quot;) confint(RStat) ## contrast estimate SE df lower.CL upper.CL ## Unburnt Prefire - Burnt Prefire 0.0795 0.1811 5206 -0.3860 0.545 ## Unburnt Prefire - Unburnt Postfire 0.1217 0.0529 5206 -0.0142 0.258 ## Unburnt Prefire - Burnt Postfire 0.2338 0.1591 5206 -0.1750 0.643 ## Burnt Prefire - Unburnt Postfire 0.0423 0.1587 5206 -0.3657 0.450 ## Burnt Prefire - Burnt Postfire 0.1543 0.0538 5206 0.0160 0.293 ## Unburnt Postfire - Burnt Postfire 0.1120 0.1326 5206 -0.2287 0.453 ## ## Results are averaged over the levels of: Season ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates References "],["create-a-visual-repersentation-of-the-model.html", "9 - Create a Visual Repersentation of the Model Visualizing the three-way interaction of Season:Status:Region Visualizing the two-way human use and season interaction Effect Size Plotting all other included interaction terms", " 9 - Create a Visual Repersentation of the Model library(glmmTMB) library(ggplot2) library(car) library(ggeffects) library(effects) library(broom) library(broom.mixed) library(emmeans) setwd(&quot;D:/DataAndAnalysis&quot;) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Datasets/FinalDatasets/ForExploration/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season&lt;- factor(Bear$Season,levels = c(&quot;Spring&quot;,&quot;Summer&quot;,&quot;Autumn&quot;)) Bear$Status&lt;-relevel(Bear$Status,&quot;Prefire&quot;) Bear$Region&lt;-relevel(Bear$Region,&quot;Unburnt&quot;) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups:Season + Season:Status + Season:Region + Region:Status + Season:Region:Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) Visualizing the three-way interaction of Season:Status:Region I will be using the function emmip to create interaction plots of the estimated marginal means based on the fitted model. This is from the package emmeans. emmip(FinalModel,~Region~Status|Season, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) Interpretation The above plot shows that in all three seasons there are decreases in bear use intensity in the post-fire landscape, however, the magnitude of these decreases vary based on both region and season. It appears that in each season there is not a significant decrease between pre-fire and post-fire bear intensity for any region however this is at odds with the emmeans output from section 08. I need to look more at the response variable here compared to the table in section 8. These estimates do not appear to match up and therefore I think I need to look further into this. Visualizing the two-way human use and season interaction emmip(FinalModel, Season ~ Number_of_Groups , at = list(Number_of_Groups = c(1:100)), type = &quot;re&quot;, CIs = TRUE, CIarg = list(lwd = 1, alpha = 0.3)) + theme_bw(base_size = 20) Interpretation As we can see in the plot above there is very different effects of the number of human groups on bear use intensity along all of the seasons. Both spring and autumn see a positive relationship of human usage and bear usage while summer sees a negative relationship. I think that a reason we may see the positive relationships in spring and autumn is that generally both humans and bears will be more active during the nicer portions of the seasons. In early spring for example few humans will be hiking on trails and bears may still be denning or will only start emerging from dens. As spring warms more humans will be hiking and more bears will be leaving their dens in search of food. Effect Size The following code plots the effect sizes of each contrast using the function eff_size from the package emmeans. emm3&lt;-emmeans(FinalModel,spec = ~ Region:Status|Season, type = &quot;response&quot;) EFF1&lt;-eff_size(emm3, sigma = sigma(FinalModel), edf = Inf, method = &quot;pairwise&quot;) plot(EFF1) Interpretation I am unsure how to interpret the results from the effect size function at this time. I had originally thought that by back transforming my emmeans (as above) I had received my effect sizes, however, these differ from the effect size function found above. I assume that these values should be the same however that may be incorrect and I will look into that further. Plotting all other included interaction terms I do not think that the other plots on this page will be as important as those above becuase those above are the highest ordered interactions. I will still present the interactions below in case they are useful. emmip(FinalModel, Region~Season, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) ## NOTE: Results may be misleading due to involvement in interactions emmip(FinalModel, Status~Season, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) ## NOTE: Results may be misleading due to involvement in interactions emmip(FinalModel, Region~Status, CIs = TRUE, type = &quot;re&quot;) + theme_bw(base_size = 20) ## NOTE: Results may be misleading due to involvement in interactions "],["simulate-from-the-model.html", "10 - Simulate from the Model", " 10 - Simulate from the Model "],["appendix---dredging-model-possibilities-with-mumin.html", "Appendix - Dredging model possibilities with MuMIn Code Table Interpretation", " Appendix - Dredging model possibilities with MuMIn I completed model dredging with the command dredge in the package MuMin (Barton 2020) to create a set of models with all possible combinations of fixed effects terms found in my global model. When creating this dredge I set the inclusion of the zero-inflation factor and the offset term as required which means they are present in all the models of the dredge. The dredge function calculates each models log-likelihood, AICc, delta AICc, and the weight against all other models. I will include the code which I used to complete the dredge function and a table of all models within 2 delta AICc. Running the function of the dredge takes upwards of 12 hours and therefore I will not include the entire output here, however, I do have a copy saved separately. Code library(glmmTMB) library(MuMIn) setwd(&quot;D:/DataAndAnalysis&quot;) #Reading in the Final Clean Data from cleaning script 7 Bear&lt;-read.csv(&quot;./Datasets/FinalDatasets/ForExploration/7_BlackAdultClean.csv&quot;,header=TRUE,stringsAsFactors = FALSE) Bear$Season&lt;-as.factor(Bear$Season) Bear$Status&lt;-as.factor(Bear$Status) Bear$Region&lt;-as.factor(Bear$Region) Bear$Season&lt;- factor(Bear$Season,levels = c(&quot;Spring&quot;,&quot;Summer&quot;,&quot;Autumn&quot;)) Bear$Status&lt;-relevel(Bear$Status,&quot;Prefire&quot;) Bear$Region&lt;-relevel(Bear$Region,&quot;Unburnt&quot;) #Creating final model. Model selection found in script 1_AdultBlackBearModelFit FinalModel&lt;-glmmTMB(Lone_Adult ~ Region + Season + Status + Number_of_Groups + Number_of_Groups*Season + Season*Status + Season*Region + Region*Status + Season*Region*Status + offset(log(Effort_per_week)) + (1|Camera_Code), data = Bear, ziformula = ~Season, na.action = na.pass, family = nbinom1(link = &quot;log&quot;)) #Completing the dredge Dredge&lt;-dredge(FinalModel, fixed = c(&quot;cond(offset(Effort_per_week))&quot;,&quot;zi(Season)&quot;)) Table cond.Int zi.Int disp.Int Humans Region Season Status Humans.Region Humans.Season Humans.Status Region.Season Region.Status Season.Status Humans.Region.Season Humans.Region.Status Humans.Season.Status Region.Season.Status Humans.Season.Status.Region offset zi df logLik AICc delta weight -3.601090 -0.6037293 0.0021143 NA NA NA NA NA NA 20 -4068.751 8177.664 0.0000000 0.1836902 -3.529966 -0.5762859 0.0022761 NA NA NA NA NA NA NA NA 16 -4072.920 8177.944 0.2798567 0.1597040 -3.602903 -0.6110782 0.0015810 NA NA NA NA NA 21 -4068.571 8179.320 1.6563612 0.0802438 -3.533596 -0.5827482 0.0017774 NA NA NA NA NA NA NA 17 -4072.759 8179.636 1.9716238 0.0685414 -3.602365 -0.6049524 0.0022582 NA NA NA NA NA 21 -4068.742 8179.662 1.9980601 0.0676414 Interpretation The dredge was completed for all possible models and these 5 models represent a weight of 0.559821 out of 335 total models. The top model of the dredge is consistent with the final model from my step wise backward selection which increases my confidence that my backward selection was done correctly. All models share the following predictors: Human groups, Region, Season, Status As well as the following interactions Human Groups:Season Region:Season Region:Status (Fire Effect) Only 3 of the top 5 model include the three way interaction of Season:Status:Region. All models included the interaction of human groups:season. All models do not include: Human Groups:Region:Season Human Groups:Region:Status Human Groups:Season:Status Human Groups:Season:Status:Region References "],["references.html", "References", " References "]]
